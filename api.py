"""
SRI å…¨å±€æ€åŠ¿æ„ŸçŸ¥ â€” FastAPI åç«¯
ä» sri_intel.db è¯»å–çœŸå®ä¸šåŠ¡æ•°æ®ï¼Œä¸º React leader-dashboard æä¾› JSON APIã€‚

å¯åŠ¨æ–¹å¼:
    uvicorn api:app --reload --port 8000
"""

import json
import os
import sqlite3
from contextlib import contextmanager
from datetime import datetime
from typing import Any

from fastapi import FastAPI, UploadFile, Form, File as FastAPIFile, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware


# â”€â”€ FastAPI App â”€â”€

app = FastAPI(
    title="SRI æƒ…æŠ¥ç³»ç»Ÿ API",
    description="ä¸º leader-dashboard React å¤§å±æä¾›å®æ—¶ä¸šåŠ¡æ•°æ®",
    version="1.0.0",
)

# CORS: å…è®¸ React dev server è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://127.0.0.1:5173",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# â”€â”€ Database Helper â”€â”€

DB_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "sri_intel.db")


@contextmanager
def get_db():
    """è·å–æ•°æ®åº“è¿æ¥ï¼ˆwith è¯­å¥è‡ªåŠ¨å…³é—­ï¼‰"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()


# â”€â”€ é˜¶æ®µæ˜ å°„ï¼šå°†è‡ªç”±æ–‡æœ¬çš„ current_stage å½’é›†åˆ° 4 å¤§æ¼æ–—æ¡¶ â”€â”€

STAGE_BUCKETS = {
    "çº¿ç´¢è·å–": ["çº¿ç´¢", "åˆæœŸæ¥è§¦", "çº¿ç´¢è·å–"],
    "æ–¹æ¡ˆæŠ¥ä»·": ["æ–¹æ¡ˆæŠ¥ä»·", "æŠ€æœ¯åƒµæŒ"],
    "å•†åŠ¡è°ˆåˆ¤": ["å•†åŠ¡è°ˆåˆ¤", "é€¼å•/ç­¾çº¦", "é€¼å•"],
    "åˆåŒç­¾çº¦": ["åˆåŒç­¾çº¦", "ç­¾çº¦", "ç«‹é¡¹", "å·²ç­¾çº¦"],
}

STAGE_ORDER = ["çº¿ç´¢è·å–", "æ–¹æ¡ˆæŠ¥ä»·", "å•†åŠ¡è°ˆåˆ¤", "åˆåŒç­¾çº¦"]
STAGE_EMOJI = {
    "çº¿ç´¢è·å–": "ğŸ“¡",
    "æ–¹æ¡ˆæŠ¥ä»·": "ğŸ“‹",
    "å•†åŠ¡è°ˆåˆ¤": "ğŸ¤",
    "åˆåŒç­¾çº¦": "âœ…",
}


def classify_stage(raw_stage: str) -> str:
    """å°†æ•°æ®åº“ä¸­çš„è‡ªç”±æ–‡æœ¬é˜¶æ®µå½’é›†åˆ°æ ‡å‡†æ¡¶"""
    if not raw_stage:
        return "çº¿ç´¢è·å–"
    for bucket, keywords in STAGE_BUCKETS.items():
        for kw in keywords:
            if kw in raw_stage:
                return bucket
    return "çº¿ç´¢è·å–"  # fallback


# â”€â”€ API Endpoints â”€â”€


@app.get("/api/health")
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "timestamp": datetime.now().isoformat()}


@app.get("/api/kpi")
def get_kpi() -> list[dict[str, Any]]:
    """
    è¿”å›é¡¶éƒ¨ 4 å¼  KPI å¡ç‰‡æ•°æ®ã€‚
    ä»çœŸå® DB èšåˆ:
      1. åœ¨è·Ÿé¡¹ç›®æ€»æ•°
      2. å…³é”®äººè¦†ç›–ç‡
      3. æœ¬æœˆæƒ…æŠ¥å½•å…¥é‡
      4. é«˜é£é™©é¡¹ç›®ï¼ˆåœæ»åœ¨çº¿ç´¢é˜¶æ®µçš„å æ¯”ï¼‰
    """
    with get_db() as conn:
        cursor = conn.cursor()

        # 1. é¡¹ç›®æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM projects")
        total_projects = cursor.fetchone()[0]

        # 2. æœ‰å…³é”®äººè¦†ç›–çš„é¡¹ç›®æ•°
        cursor.execute(
            "SELECT COUNT(DISTINCT project_id) FROM stakeholders"
        )
        projects_with_stakeholders = cursor.fetchone()[0]
        coverage_rate = (
            round(projects_with_stakeholders / total_projects * 100, 1)
            if total_projects > 0
            else 0
        )

        # 3. æƒ…æŠ¥å½•å…¥é‡ï¼ˆvisit_logs æ€»æ¡æ•°ï¼‰
        cursor.execute("SELECT COUNT(*) FROM visit_logs")
        total_logs = cursor.fetchone()[0]

        # 4. é«˜é£é™©ï¼šåœç•™åœ¨"çº¿ç´¢"é˜¶æ®µçš„é¡¹ç›®æ•°
        cursor.execute("SELECT current_stage FROM projects")
        stages = [row[0] for row in cursor.fetchall()]
        risk_count = sum(
            1 for s in stages if classify_stage(s or "") == "çº¿ç´¢è·å–"
        )

    return [
        {
            "id": "projects",
            "emoji": "ğŸ’°",
            "title": "åœ¨è·Ÿé¡¹ç›®æ€»æ•°",
            "value": f"{total_projects} ä¸ª",
            "trend": "+3 æœ¬æœˆæ–°å¢",
            "trendUp": True,
            "accentColor": "border-l-blue-500",
            "description": "å½“å‰ç³»ç»Ÿä¸­æ‰€æœ‰æ´»è·ƒé¡¹ç›®æ•°é‡",
        },
        {
            "id": "coverage",
            "emoji": "ğŸ¯",
            "title": "å…³é”®äººè¦†ç›–ç‡",
            "value": f"{coverage_rate}%",
            "trend": f"{projects_with_stakeholders}/{total_projects} é¡¹ç›®",
            "trendUp": coverage_rate >= 50,
            "accentColor": "border-l-emerald-500",
            "description": "å·²å»ºç«‹å…³é”®äººæ¡£æ¡ˆçš„é¡¹ç›®å æ¯”",
        },
        {
            "id": "intel",
            "emoji": "ğŸ“¡",
            "title": "ç´¯è®¡æƒ…æŠ¥å½•å…¥",
            "value": f"{total_logs} æ¡",
            "trend": "æŒç»­æ›´æ–°ä¸­",
            "trendUp": True,
            "accentColor": "border-l-amber-500",
            "description": "æ‰€æœ‰æ‹œè®¿æ—¥å¿—å’Œæƒ…æŠ¥ä¸ŠæŠ¥æ€»æ¡æ•°",
        },
        {
            "id": "risk",
            "emoji": "ğŸš¨",
            "title": "é«˜é£é™©åœæ»é¡¹ç›®",
            "value": f"{risk_count} ä¸ª",
            "trend": f"å æ¯” {round(risk_count / total_projects * 100)}%"
            if total_projects > 0
            else "â€”",
            "trendUp": False,
            "accentColor": "border-l-red-500",
            "description": "ä»åœç•™åœ¨çº¿ç´¢é˜¶æ®µçš„é¡¹ç›®ï¼Œéœ€é‡ç‚¹æ¨è¿›",
        },
    ]


@app.get("/api/pipeline")
def get_pipeline() -> list[dict[str, Any]]:
    """
    è¿”å›æˆ˜åŒºæ¼æ–—æ•°æ®ã€‚
    å°† projects.current_stage å½’é›†åˆ° 4 å¤§æ ‡å‡†æ¡¶ï¼Œ
    è¿”å›å„æ¡¶çš„é¡¹ç›®æ•°å’Œå½’ä¸€åŒ–ç™¾åˆ†æ¯”ã€‚
    """
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT current_stage FROM projects")
        stages = [row[0] or "" for row in cursor.fetchall()]

    # ç»Ÿè®¡å„æ¡¶
    bucket_counts: dict[str, int] = {s: 0 for s in STAGE_ORDER}
    for raw in stages:
        bucket = classify_stage(raw)
        bucket_counts[bucket] += 1

    total = len(stages) or 1
    max_count = max(bucket_counts.values()) or 1

    result = []
    for stage_name in STAGE_ORDER:
        count = bucket_counts[stage_name]
        result.append(
            {
                "label": stage_name,
                "emoji": STAGE_EMOJI[stage_name],
                "count": count,
                "amount": f"{count} ä¸ªé¡¹ç›®",
                "widthPercent": round(count / max_count * 100),
            }
        )

    return result


@app.get("/api/feed")
def get_feed() -> list[dict[str, Any]]:
    """
    è¿”å›æœ€æ–° 10 æ¡æƒ…æŠ¥æˆ˜æŠ¥æµã€‚
    ä» visit_logs JOIN projects ä¸­èšåˆã€‚
    """
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute(
            """
            SELECT
                v.log_id,
                v.project_id,
                p.project_name,
                COALESCE(p.applicant, 'å‰çº¿é”€å”®'),
                COALESCE(p.dept, ''),
                v.raw_input,
                v.ai_parsed_data,
                v.created_at
            FROM visit_logs v
            LEFT JOIN projects p ON v.project_id = p.project_id
            ORDER BY v.log_id DESC
            LIMIT 10
            """
        )
        rows = cursor.fetchall()

    feed_items = []
    role_map = {
        "": ("ä¸€çº¿é”€å”®", "ğŸ›¡ï¸", "info"),
        "åå—æˆ˜åŒº": ("ä¸€çº¿é”€å”®", "ğŸ›¡ï¸", "info"),
        "åä¸œæˆ˜åŒº": ("ä¸€çº¿é”€å”®", "ğŸ›¡ï¸", "info"),
        "ååŒ—æˆ˜åŒº": ("ä¸€çº¿é”€å”®", "ğŸ›¡ï¸", "info"),
    }

    for i, row in enumerate(rows):
        log_id = row[0]
        project_name = row[2] or "æœªçŸ¥é¡¹ç›®"
        author = row[3] or "å‰çº¿é”€å”®"
        dept = row[4] or ""
        raw_input = row[5] or ""
        ai_parsed = row[6] or ""
        created_at = row[7]

        # ä» raw_input æå–ç®€è¦ action æè¿°
        action = _extract_action(raw_input, ai_parsed)

        # æ ¼å¼åŒ–æ—¶é—´
        timestamp = _format_timestamp(created_at)

        # æ ¹æ®å†…å®¹åˆ¤æ–­ç±»å‹
        feed_type = _classify_feed_type(raw_input, ai_parsed)

        # è§’è‰²ä¿¡æ¯
        role_info = role_map.get(dept, ("ä¸€çº¿é”€å”®", "ğŸ›¡ï¸", "info"))
        author_initial = author[0] if author else "?"

        feed_items.append(
            {
                "id": f"f{log_id}",
                "author": author,
                "authorInitial": author_initial,
                "role": role_info[0],
                "roleEmoji": role_info[1],
                "roleBadgeColor": role_info[2],
                "action": action,
                "project": project_name,
                "timestamp": timestamp,
                "type": feed_type,
            }
        )

    return feed_items


# â”€â”€ Helper Functions â”€â”€


def _extract_action(raw_input: str, ai_parsed: str) -> str:
    """ä»æ—¥å¿—å†…å®¹ä¸­æå–ç®€è¦è¡ŒåŠ¨æè¿°"""
    if not raw_input:
        return "æäº¤äº†ä¸€æ¡æƒ…æŠ¥"

    # å¦‚æœåŒ…å«ç‰¹æ®Šæ ‡è®°
    if "[ç«‹é¡¹èƒŒæ™¯åŸºåº§æ›´æ–°]" in raw_input:
        return "æ›´æ–°äº†é¡¹ç›®ç«‹é¡¹åŸºåº§ä¿¡æ¯"

    # AI è§£ææ•°æ®ä¸­æå–æ‘˜è¦
    if ai_parsed:
        try:
            parsed = json.loads(ai_parsed)
            summary = parsed.get("tl_dr") or parsed.get("summary") or ""
            if summary:
                return summary[:50] + ("..." if len(summary) > 50 else "")
        except (json.JSONDecodeError, TypeError):
            pass

    # æˆªå– raw_input å‰ 40 å­—ç¬¦
    clean = raw_input.strip().strip('"').strip("'")
    if len(clean) > 40:
        return f"ä¸ŠæŠ¥æƒ…æŠ¥ï¼š{clean[:40]}..."
    return f"ä¸ŠæŠ¥æƒ…æŠ¥ï¼š{clean}" if clean else "æäº¤äº†ä¸€æ¡æƒ…æŠ¥"


def _format_timestamp(created_at: str | None) -> str:
    """å°†æ—¶é—´æˆ³æ ¼å¼åŒ–ä¸ºç›¸å¯¹æ—¶é—´"""
    if not created_at:
        return "è¾ƒæ—©å‰"
    try:
        dt = datetime.fromisoformat(created_at)
        delta = datetime.now() - dt
        if delta.days > 30:
            return f"{delta.days // 30} ä¸ªæœˆå‰"
        if delta.days > 0:
            return f"{delta.days} å¤©å‰"
        hours = delta.seconds // 3600
        if hours > 0:
            return f"{hours} å°æ—¶å‰"
        minutes = delta.seconds // 60
        return f"{minutes} åˆ†é’Ÿå‰" if minutes > 0 else "åˆšåˆš"
    except (ValueError, TypeError):
        return "è¾ƒæ—©å‰"


def _classify_feed_type(raw_input: str, ai_parsed: str) -> str:
    """æ ¹æ®å†…å®¹åˆ¤æ–­æˆ˜æŠ¥ç±»å‹"""
    combined = (raw_input or "") + (ai_parsed or "")
    if any(kw in combined for kw in ["ç­¾çº¦", "ç­¾å•", "ä¸­æ ‡", "æˆåŠŸ"]):
        return "success"
    if any(kw in combined for kw in ["é£é™©", "é¢„è­¦", "æ’å•", "æ‹¦æˆª", "é©³å›"]):
        return "destructive"
    if any(kw in combined for kw in ["å®¡æ‰¹", "ä»²è£", "å¾…", "ç­‰å¾…"]):
        return "warning"
    return "info"


# â”€â”€ CRM é¡¹ç›®åˆ—è¡¨ â”€â”€

STAGE_BADGE_VARIANT = {
    "çº¿ç´¢è·å–": "info",
    "æ–¹æ¡ˆæŠ¥ä»·": "warning",
    "å•†åŠ¡è°ˆåˆ¤": "secondary",
    "åˆåŒç­¾çº¦": "success",
}


@app.get("/api/crm/projects")
def get_crm_projects() -> list[dict[str, Any]]:
    """
    è¿”å›å…¨é‡é¡¹ç›®è¯¦æƒ…ï¼ˆCRM è¡¨æ ¼ç”¨ï¼‰ã€‚
    èšåˆï¼šé¡¹ç›®åŸºæœ¬ä¿¡æ¯ + å…³é”®äººæ•°é‡ + æœ€æ–°è·Ÿè¿›æ‘˜è¦ã€‚
    """
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute(
            """
            SELECT
                p.project_id,
                p.project_name,
                COALESCE(p.current_stage, '') AS current_stage,
                COALESCE(p.client, '') AS client,
                COALESCE(p.applicant, '') AS applicant,
                COALESCE(p.dept, '') AS dept,
                (SELECT COUNT(*) FROM stakeholders s
                 WHERE s.project_id = p.project_id) AS stakeholder_count,
                (SELECT SUBSTR(COALESCE(v.raw_input, ''), 1, 60)
                 FROM visit_logs v
                 WHERE v.project_id = p.project_id
                 ORDER BY v.log_id DESC LIMIT 1) AS latest_log,
                (SELECT v.created_at
                 FROM visit_logs v
                 WHERE v.project_id = p.project_id
                 ORDER BY v.log_id DESC LIMIT 1) AS latest_log_time
            FROM projects p
            ORDER BY p.project_id DESC
            """
        )
        rows = cursor.fetchall()

    result = []
    for row in rows:
        raw_stage = row[2]
        bucket = classify_stage(raw_stage)
        latest_log_raw = (row[7] or "").strip().strip('"').strip("'")

        result.append(
            {
                "id": row[0],
                "name": row[1] or f"é¡¹ç›®_{row[0]}",
                "stage": bucket,
                "rawStage": raw_stage,
                "client": row[3] or "â€”",
                "applicant": row[4] or "â€”",
                "dept": row[5] or "â€”",
                "stakeholderCount": row[6],
                "latestLog": latest_log_raw[:60] if latest_log_raw else "æš‚æ— è·Ÿè¿›è®°å½•",
                "latestLogTime": _format_timestamp(row[8]),
                "stageColor": STAGE_BADGE_VARIANT.get(bucket, "info"),
            }
        )

    return result


# â”€â”€ å…¥å£ â”€â”€


@app.get("/api/projects")
def get_projects_list() -> list[dict[str, Any]]:
    """è¿”å›é¡¹ç›®åˆ—è¡¨ï¼ˆä¾›å‰ç«¯ä¸‹æ‹‰æ¡†ä½¿ç”¨ï¼‰ï¼ŒåŒ…å«å®¢æˆ·/è®¾è®¡é™¢/ææŠ¥äºº/æˆ˜åŒº"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute(
            "SELECT project_id, project_name, "
            "COALESCE(current_stage, '') as stage, "
            "COALESCE(client, '') as client, "
            "COALESCE(design_institute, '') as design_institute, "
            "COALESCE(applicant, '') as applicant, "
            "COALESCE(dept, '') as dept "
            "FROM projects ORDER BY project_id"
        )
        rows = cursor.fetchall()

    return [
        {
            "id": row[0],
            "name": row[1] or f"é¡¹ç›®_{row[0]}",
            "stage": row[2],
            "client": row[3],
            "design_institute": row[4],
            "applicant": row[5],
            "dept": row[6],
        }
        for row in rows
    ]

# â”€â”€ æ–°å»ºé¡¹ç›®å®¡æ‰¹æµ (å¤åˆ» app.py L540-668) â”€â”€

# å†…å­˜çº§å®¡æ ¸æ±  & ç”³è¯‰æ± 
_pending_projects: list[dict] = []
_appeals: list[dict] = []
_next_pending_id = 1


@app.post("/api/projects/create")
async def create_project(request: Request):
    """æ–°å»ºé¡¹ç›®ï¼Œå«æŸ¥é‡ï¼ˆä¿ç•™å…¼å®¹ï¼‰ã€‚"""
    body = await request.json()
    name = body.get("name", "").strip()
    if not name:
        return JSONResponse(content={"error": "é¡¹ç›®åç§°ä¸èƒ½ä¸ºç©º"}, status_code=400)

    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT project_id FROM projects WHERE project_name = ?", (name,))
        existing = cursor.fetchone()
    if existing:
        return JSONResponse(
            content={"error": f"é¡¹ç›®ã€{name}ã€‘å·²å­˜åœ¨ (ID: {existing[0]})ï¼Œè¯·æ¢ä¸€ä¸ªåç§°ã€‚"},
            status_code=409,
        )

    from database import add_project
    new_id = add_project(
        project_name=name,
        current_stage=body.get("stage", "çº¿ç´¢"),
        client=body.get("client", ""),
        design_institute=body.get("design_institute", ""),
        general_contractor=body.get("general_contractor", ""),
        applicant=body.get("applicant", ""),
        dept=body.get("dept", ""),
    )
    return {"success": True, "project_id": new_id, "message": f"é¡¹ç›®ã€{name}ã€‘åˆ›å»ºæˆåŠŸï¼"}


@app.post("/api/projects/submit")
async def submit_project(request: Request):
    """
    æäº¤ç«‹é¡¹ç”³è¯· (ä¸ç›´æ¥å…¥åº“)ã€‚
    æ‰§è¡Œ AI æ¨¡ç³Šæ’å•æ£€æŸ¥ï¼šå®¢æˆ·åäº’ç›¸åŒ…å«å³è§†ä¸ºé«˜å±æ’å•ã€‚
    """
    global _next_pending_id
    body = await request.json()
    client = body.get("client", "").strip()
    name = body.get("name", "").strip()
    if not name or not client:
        return JSONResponse(content={"error": "å®¢æˆ·åå’Œé¡¹ç›®åä¸èƒ½ä¸ºç©º"}, status_code=400)

    # â”€â”€ 1. ç²¾ç¡®æŸ¥é‡ï¼šåŒåé¡¹ç›® â”€â”€
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT project_id FROM projects WHERE project_name = ?", (name,))
        exact = cursor.fetchone()
    if exact:
        return JSONResponse(
            content={"error": f"é¡¹ç›®ã€{name}ã€‘å·²å­˜åœ¨ (ID: {exact[0]})ã€‚"},
            status_code=409,
        )

    # â”€â”€ 2. AI æ¨¡ç³Šæ’å•å¼•æ“ï¼šå®¢æˆ·åäº’ç›¸åŒ…å« â”€â”€
    conflict_found = None
    conflict_type = ""
    conflict_owner = "æœªçŸ¥é”€å”®"

    # 2a. æ­£å¼é¡¹ç›®åº“
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute(
            "SELECT project_name, COALESCE(client, '') as client, "
            "COALESCE(applicant, 'å†å²å½’å±äºº') as applicant FROM projects"
        )
        for row in cursor.fetchall():
            existing_client = row[1]
            if existing_client and (client in existing_client or existing_client in client):
                conflict_found = row[0]
                conflict_type = "æ­£å¼é¡¹ç›®åº“"
                conflict_owner = row[2]
                break

    # 2b. å®¡æ ¸æ± æ’é˜Ÿä¸­
    if not conflict_found:
        for p in _pending_projects:
            existing_client = p.get("client", "")
            if existing_client and (client in existing_client or existing_client in client):
                conflict_found = p.get("project_name", "")
                conflict_type = "å®¡æ ¸æ± æ’é˜Ÿä¸­"
                conflict_owner = p.get("applicant", "å…¶ä»–é”€å”®")
                break

    # â”€â”€ 3. æ‹¦æˆªåˆ†æµ â”€â”€
    if conflict_found:
        return {
            "success": False,
            "conflict": True,
            "conflictProject": conflict_found,
            "conflictType": conflict_type,
            "conflictOwner": conflict_owner,
        }

    # â”€â”€ 4. ç»¿ç¯æ”¾è¡Œ â†’ æ¨å…¥å®¡æ ¸æ±  â”€â”€
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    pending_item = {
        "id": _next_pending_id,
        "client": client,
        "project_name": name,
        "design_institute": body.get("design_institute", ""),
        "general_contractor": body.get("general_contractor", ""),
        "applicant": body.get("applicant", "æœªçŸ¥"),
        "dept": body.get("dept", "æœªçŸ¥æˆ˜åŒº"),
        "stage": body.get("stage", "çº¿ç´¢"),
        "time": timestamp,
    }
    _pending_projects.append(pending_item)
    _next_pending_id += 1

    return {
        "success": True,
        "pending": True,
        "message": f"ææŠ¥æˆåŠŸï¼é¡¹ç›®ã€{name}ã€‘å·²æ¨é€è‡³æ€»ç›‘å®¡æ ¸æ± ã€‚",
    }


@app.post("/api/projects/appeal")
async def appeal_project(request: Request):
    """æäº¤æ’å•å½’å±æƒå¤æ ¸ç”³è¯‰ã€‚"""
    body = await request.json()
    reason = body.get("reason", "").strip()
    if not reason:
        return JSONResponse(content={"error": "è¯·å¿…é¡»å¡«å†™ç”³è¯‰ä¾æ®ï¼"}, status_code=400)

    _appeals.append({
        "id": len(_appeals) + 1,
        "new_project": body.get("new_project", ""),
        "conflict_with": body.get("conflict_with", ""),
        "original_owner": body.get("original_owner", ""),
        "applicant": body.get("applicant", "æœªçŸ¥"),
        "reason": reason,
        "has_evidence": body.get("has_evidence", False),
        "status": "âš–ï¸ å¾…è£å†³",
        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    })
    return {
        "success": True,
        "message": "ç”³è¯‰å·²æäº¤è‡³ VPï¼åŸå½’å±äººå°†è¢«é€šçŸ¥ã€‚è¯·ç­‰å¾…æ³•åº­è£å†³ã€‚",
    }


@app.get("/api/projects/pending")
def get_pending_projects():
    """è·å–å¾…å®¡æ ¸é¡¹ç›®åˆ—è¡¨ã€‚"""
    return {"pending": _pending_projects, "appeals": _appeals}


@app.post("/api/projects/approve")
async def approve_project(request: Request):
    """å®¡æ ¸é€šè¿‡ï¼šä»å®¡æ ¸æ± ç§»é™¤å¹¶å†™å…¥æ­£å¼æ•°æ®åº“ã€‚"""
    body = await request.json()
    pending_id = body.get("id")

    target = None
    for p in _pending_projects:
        if p["id"] == pending_id:
            target = p
            break
    if not target:
        return JSONResponse(content={"error": "æœªæ‰¾åˆ°è¯¥å¾…å®¡é¡¹ç›®"}, status_code=404)

    # å†™å…¥æ•°æ®åº“
    from database import add_project
    new_id = add_project(
        project_name=target["project_name"],
        current_stage=target.get("stage", "çº¿ç´¢"),
        client=target.get("client", ""),
        design_institute=target.get("design_institute", ""),
        general_contractor=target.get("general_contractor", ""),
        applicant=target.get("applicant", ""),
        dept=target.get("dept", ""),
    )

    _pending_projects.remove(target)
    return {
        "success": True,
        "project_id": new_id,
        "message": f"å®¡æ ¸é€šè¿‡ï¼é¡¹ç›®ã€{target['project_name']}ã€‘å·²å†™å…¥æ•°æ®åº“ã€‚",
    }


@app.post("/api/projects/reject")
async def reject_project(request: Request):
    """é©³å›ï¼šä»å®¡æ ¸æ± ç§»é™¤ã€‚"""
    body = await request.json()
    pending_id = body.get("id")

    target = None
    for p in _pending_projects:
        if p["id"] == pending_id:
            target = p
            break
    if not target:
        return JSONResponse(content={"error": "æœªæ‰¾åˆ°è¯¥å¾…å®¡é¡¹ç›®"}, status_code=404)

    _pending_projects.remove(target)
    return {"success": True, "message": f"å·²é©³å›é¡¹ç›®ã€{target['project_name']}ã€‘ã€‚"}


# â”€â”€ æ—¥å¸¸æ¨è¿›åŠ¨æ€ & å›¾ç‰‡æƒ…æŠ¥ â”€â”€


@app.post("/api/intel/daily_log")
async def daily_log(request: Request):
    """
    æ¥æ”¶æ—¥å¸¸æ¨è¿›æ–‡æœ¬ï¼Œè°ƒç”¨ AI è§£æä¸º 4+1 ç»“æ„åŒ–æƒ…æŠ¥å¹¶å­˜å…¥æ•°æ®åº“ã€‚
    """
    body = await request.json()
    project_id = body.get("project_id")
    raw_text = body.get("text", "").strip()
    llm_configs = body.get("llm_configs", None)
    api_key = request.headers.get("X-API-Key", "").strip()
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY", "")
    # å¦‚æœ llm_configs ä¸­æœ‰ä»»ä½•æœ‰æ•ˆ keyï¼Œä¹Ÿå¯ä»¥ä¸è¦æ±‚é¡¶å±‚ apiKey
    has_any_key = bool(api_key)
    if llm_configs:
        for p in ["openai", "gemini", "anthropic", "xai"]:
            if llm_configs.get(p, {}).get("enabled") and llm_configs.get(p, {}).get("apiKey"):
                has_any_key = True
                break

    if not project_id:
        return JSONResponse(content={"error": "ç¼ºå°‘ project_id"}, status_code=400)
    if not raw_text:
        return JSONResponse(content={"error": "è¯·è¾“å…¥æ¨è¿›å†…å®¹"}, status_code=400)
    if not has_any_key:
        return JSONResponse(content={"error": "è¯·å…ˆåœ¨å³ä¸Šè§’ âš™ï¸ ç³»ç»Ÿè®¾ç½®ä¸­è¾“å…¥æœ‰æ•ˆçš„ API Key"}, status_code=401)

    try:
        from llm_service import build_llm_router
        router = build_llm_router(primary_api_key=api_key, llm_configs=llm_configs)
        from llm_service import SYSTEM_PROMPT
        parsed_json_str = router.chat(
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": raw_text[:4000]},
            ],
            temperature=0.2,
        )
    except Exception as e:
        return {"success": False, "error": f"AI è§£æå¤±è´¥: {str(e)}"}

    # å­˜å…¥æ•°æ®åº“
    try:
        from database import save_intelligence
        save_intelligence(project_id, raw_text[:2000], parsed_json_str)
    except Exception as e:
        print(f"âš ï¸ æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")

    # è§£æè¿”å›
    try:
        intelligence = json.loads(parsed_json_str)
    except (json.JSONDecodeError, TypeError):
        intelligence = {"raw_response": parsed_json_str}

    return {"success": True, "intelligence": intelligence, "message": "âœ… æ—¥å¸¸æ¨è¿›æƒ…æŠ¥å·²å…¥åº“ï¼"}


@app.post("/api/intel/upload_image")
async def upload_image(
    request: Request,
    file: UploadFile = FastAPIFile(...),
    project_id: int = Form(1),
):
    """
    æ¥æ”¶ç°åœºç…§ç‰‡ (JPG/PNG)ï¼Œè°ƒç”¨ GPT-4o-mini å¤šæ¨¡æ€è§†è§‰è§£æï¼Œ
    æå–å“ç‰Œã€å‹å·ã€å…³é”®å‚æ•°ï¼Œå¹¶ç»™å‡ºé”€å”®å»ºè®®ã€‚
    """
    import base64 as _b64

    api_key = request.headers.get("X-API-Key", "").strip()
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key:
        return {"success": False, "error": "è¯·å…ˆé…ç½® API Key"}

    filename = file.filename or "unknown"
    suffix = filename.rsplit(".", 1)[-1].lower() if "." in filename else ""
    if suffix not in ("jpg", "jpeg", "png"):
        return {"success": False, "error": f"ä¸æ”¯æŒçš„å›¾ç‰‡ç±»å‹: .{suffix}ã€‚ä»…æ”¯æŒ JPG/PNG"}

    file_bytes = await file.read()
    if len(file_bytes) == 0:
        return {"success": False, "error": "æ–‡ä»¶å†…å®¹ä¸ºç©º"}

    try:
        b64_img = _b64.b64encode(file_bytes).decode("utf-8")
        vision_prompt = "è¯·æå–è¿™å¼ ä¸šåŠ¡ç…§ç‰‡ä¸­çš„å“ç‰Œã€å‹å·ã€å…³é”®å‚æ•°ï¼Œå¹¶ç»™å‡ºé”€å”®å»ºè®®ã€‚"

        if api_key.startswith("sk-ant-"):
            # Anthropic Claude è§†è§‰ API
            import anthropic
            client = anthropic.Anthropic(api_key=api_key)
            response = client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=2000,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image", "source": {"type": "base64", "media_type": f"image/{suffix}", "data": b64_img}},
                        {"type": "text", "text": vision_prompt},
                    ],
                }],
            )
            parsed_intel = response.content[0].text
        else:
            # OpenAI GPT-4o è§†è§‰ API
            from openai import OpenAI as _OpenAI_img
            client = _OpenAI_img(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": vision_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/{suffix};base64,{b64_img}"}},
                    ],
                }],
            )
            parsed_intel = response.choices[0].message.content or ""
    except Exception as e:
        return {"success": False, "error": f"å›¾ç‰‡è§£æå¤±è´¥: {str(e)}"}

    # å­˜å…¥æ•°æ®åº“
    full_text = f"ã€ğŸš¨ æ·±åº¦æ–‡æ¡£/è§†è§‰æƒ…æŠ¥æå–ã€‘\n{parsed_intel}"
    try:
        from database import save_intelligence
        save_intelligence(project_id, f"[å›¾ç‰‡æƒ…æŠ¥] {filename}", full_text)
    except Exception as e:
        print(f"âš ï¸ æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")

    return {
        "success": True,
        "filename": filename,
        "parsed_intel": parsed_intel,
        "message": "âœ… ç°åœºå›¾ç‰‡æƒ…æŠ¥å·²è§£æå¹¶å…¥åº“ï¼",
    }


@app.post("/api/intel/upload_media")
async def upload_media(
    request: Request,
    file: UploadFile = FastAPIFile(...),
    project_id: int = Form(1),
):
    """
    æ¥æ”¶éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ (MP3/WAV/M4A/MP4/MOV)ï¼Œ
    ä½¿ç”¨ Whisper è½¬æ–‡å­—ï¼Œå†è°ƒç”¨ AI è§£æä¸ºç»“æ„åŒ–æƒ…æŠ¥ã€‚
    """
    api_key = request.headers.get("X-API-Key", "").strip()
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY", "")
    if not api_key:
        return {"success": False, "error": "è¯·å…ˆé…ç½® API Key"}

    filename = file.filename or "unknown"
    suffix = filename.rsplit(".", 1)[-1].lower() if "." in filename else ""
    allowed = ("mp3", "wav", "m4a", "mp4", "mov", "webm", "ogg", "flac")
    if suffix not in allowed:
        return {"success": False, "error": f"ä¸æ”¯æŒçš„åª’ä½“ç±»å‹: .{suffix}ã€‚æ”¯æŒ {', '.join(allowed)}"}

    file_bytes = await file.read()
    if len(file_bytes) == 0:
        return {"success": False, "error": "æ–‡ä»¶å†…å®¹ä¸ºç©º"}

    # Step 1: Whisper è½¬å½•ï¼ˆéœ€è¦ OpenAI Keyï¼‰
    import tempfile
    whisper_key = api_key
    if api_key.startswith("sk-ant-"):
        # Anthropic Key ä¸èƒ½ç”¨ Whisperï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å– OpenAI Key
        whisper_key = os.environ.get("OPENAI_API_KEY", "")
        if not whisper_key or whisper_key.startswith("sk-ant-"):
            return {"success": False, "error": "éŸ³é¢‘è½¬å½•éœ€è¦ OpenAI API Keyï¼ˆWhisper æœåŠ¡ï¼‰ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼Œæˆ–ä½¿ç”¨ OpenAI å¯†é’¥ã€‚"}
    try:
        from openai import OpenAI as _OpenAI_media
        client = _OpenAI_media(api_key=whisper_key)

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆWhisper API éœ€è¦æ–‡ä»¶å¯¹è±¡ï¼‰
        with tempfile.NamedTemporaryFile(suffix=f".{suffix}", delete=False) as tmp:
            tmp.write(file_bytes)
            tmp_path = tmp.name

        with open(tmp_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="zh",
            )
        transcribed_text = transcript.text
        os.unlink(tmp_path)
    except Exception as e:
        return {"success": False, "error": f"éŸ³é¢‘è½¬å½•å¤±è´¥: {str(e)}"}

    if not transcribed_text.strip():
        return {"success": False, "error": "è½¬å½•ç»“æœä¸ºç©ºï¼Œæœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³å†…å®¹"}

    # Step 2: AI è§£æè½¬å½•æ–‡æœ¬
    try:
        from llm_service import parse_visit_log
        parsed_json_str = parse_visit_log(api_key, transcribed_text[:4000])
    except Exception as e:
        parsed_json_str = f"è½¬å½•æˆåŠŸä½† AI è§£æå¤±è´¥: {str(e)}"

    # Step 3: å­˜å…¥æ•°æ®åº“
    try:
        from database import save_intelligence
        save_intelligence(project_id, transcribed_text[:2000], parsed_json_str)
    except Exception as e:
        print(f"âš ï¸ æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")

    # è§£æè¿”å›
    try:
        intelligence = json.loads(parsed_json_str)
    except (json.JSONDecodeError, TypeError):
        intelligence = {"raw_response": parsed_json_str}

    return {
        "success": True,
        "filename": filename,
        "transcribed_text": transcribed_text,
        "intelligence": intelligence,
        "message": f"âœ… éŸ³é¢‘/è§†é¢‘è½¬å½•å®Œæˆï¼ˆ{len(transcribed_text)}å­—ï¼‰ï¼Œæƒ…æŠ¥å·²å…¥åº“ï¼",
    }

# â”€â”€ æˆ˜å½¹ç«‹é¡¹åŸºåº§ (åŸç‰ˆ app.py L745-800) â”€â”€


@app.post("/api/intel/save_baseline")
async def save_baseline(request: Request):
    """
    ä¿å­˜é¡¹ç›®æˆ˜å½¹ç«‹é¡¹åŸºåº§(ç¡¬æ€§èƒŒæ™¯æŒ‡æ ‡)ï¼Œä½œä¸ºé«˜æƒé‡æƒ…æŠ¥æ³¨å…¥æ•°æ®åº“ã€‚
    """
    from database import save_intelligence
    body = await request.json()
    project_id = body.get("project_id")
    info_source = body.get("info_source", "")
    project_driver = body.get("project_driver", "")
    position = body.get("position", "")
    budget_status = body.get("budget_status", "")

    if not project_id:
        return JSONResponse(content={"error": "ç¼ºå°‘ project_id"}, status_code=400)

    baseline_intel = (
        f"ã€ğŸš¨ ç³»ç»Ÿæ ‡è®°ï¼šæ ¸å¿ƒç«‹é¡¹èƒŒæ™¯åŸºåº§ã€‘\n"
        f"- ä¿¡æ¯æ¥æºï¼š{info_source}\n"
        f"- æ ¸å¿ƒé©±åŠ¨åŠ›ï¼š{project_driver}\n"
        f"- æˆ‘æ–¹å½“å‰èº«ä½ï¼š{position}\n"
        f"- é¢„ç®—çŠ¶æ€ï¼š{budget_status}\n"
        f"ï¼ˆAIå‚è°‹è¯·æ³¨æ„ï¼šæ­¤ä¸ºé¡¹ç›®åº•å±‚ç¡¬æ€§çº¦æŸï¼Œ"
        f"åç»­æ‰€æœ‰ç­–ç•¥åˆ†æå¿…é¡»åŸºäºæ­¤èƒŒæ™¯ï¼ï¼‰"
    )

    try:
        save_intelligence(project_id, "[ç«‹é¡¹èƒŒæ™¯åŸºåº§æ›´æ–°]", baseline_intel)
        position_tag = position.split(" ")[0] if position else "æœªçŸ¥"
        return {"success": True, "message": f"æˆ˜å½¹åŸºåº§å·²é”å®šï¼AI å·²æ„ŸçŸ¥æˆ‘æ–¹å½“å‰å¤„äºã€{position_tag}ã€‘çŠ¶æ€ã€‚"}
    except Exception as e:
        return JSONResponse(content={"error": f"ä¿å­˜å¤±è´¥: {str(e)}"}, status_code=500)


@app.post("/api/upload_and_analyze")
async def upload_and_analyze(
    request: Request,
    file: UploadFile = FastAPIFile(...),
    project_id: int = Form(1),
):
    """
    æ¥æ”¶æ–‡ä»¶ä¸Šä¼ ï¼Œæå–æ–‡æœ¬ï¼Œè°ƒç”¨ LLM è§£æä¸ºç»“æ„åŒ–æƒ…æŠ¥ï¼Œå­˜å…¥æ•°æ®åº“ã€‚

    - æ”¯æŒ: .pdf / .docx / .txt
    - API Key é€šè¿‡ X-API-Key header ä¼ å…¥
    - è¿”å› 4+1 JSON ç»“æ„åŒ–æƒ…æŠ¥
    """
    import sys
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

    # --- 1. è·å– API Key ---
    api_key = request.headers.get("x-api-key", "") or ""
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY", "")

    # --- 2. æ–‡ä»¶ç±»å‹æ ¡éªŒ ---
    filename = file.filename or "unknown"
    suffix = filename.rsplit(".", 1)[-1].lower() if "." in filename else ""

    if suffix not in ("pdf", "docx", "txt"):
        return {
            "success": False,
            "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: .{suffix}ã€‚ä»…æ”¯æŒ PDF / DOCX / TXT",
        }

    # --- 3. è¯»å–æ–‡ä»¶å†…å®¹ ---
    file_bytes = await file.read()
    if len(file_bytes) == 0:
        return {"success": False, "error": "æ–‡ä»¶å†…å®¹ä¸ºç©º"}

    # --- 4. æå–æ–‡æœ¬ ---
    extracted_text = ""

    if suffix == "pdf":
        try:
            import io
            import PyPDF2

            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
            pages_text = []
            for page in pdf_reader.pages:
                text = page.extract_text()
                if text:
                    pages_text.append(text)
            extracted_text = "\n".join(pages_text)
        except Exception as e:
            return {"success": False, "error": f"PDF è§£æå¤±è´¥: {str(e)}"}

    elif suffix == "docx":
        try:
            import io
            from docx import Document

            doc = Document(io.BytesIO(file_bytes))
            paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]
            extracted_text = "\n".join(paragraphs)
        except Exception as e:
            return {"success": False, "error": f"DOCX è§£æå¤±è´¥: {str(e)}"}

    elif suffix == "txt":
        try:
            extracted_text = file_bytes.decode("utf-8")
        except UnicodeDecodeError:
            try:
                extracted_text = file_bytes.decode("gbk")
            except UnicodeDecodeError:
                return {"success": False, "error": "TXT æ–‡ä»¶ç¼–ç æ— æ³•è¯†åˆ«"}

    if not extracted_text.strip():
        return {"success": False, "error": "æ–‡ä»¶ä¸­æœªæå–åˆ°æœ‰æ•ˆæ–‡æœ¬å†…å®¹"}

    # --- 5. è°ƒç”¨ LLM è§£æ ---
    try:
        from llm_service import parse_visit_log

        if not api_key:
            return {
                "success": False,
                "error": "æœªæä¾› API Keyã€‚è¯·åœ¨è®¾ç½®ä¸­è¾“å…¥ OpenAI API Key",
            }

        parsed_json_str = parse_visit_log(api_key, extracted_text[:4000])
    except Exception as e:
        return {"success": False, "error": f"AI è§£æå¤±è´¥: {str(e)}"}

    # --- 6. å­˜å…¥æ•°æ®åº“ ---
    try:
        from database import save_intelligence

        save_intelligence(project_id, extracted_text[:2000], parsed_json_str)
    except Exception as e:
        # å­˜å‚¨å¤±è´¥ä¸å½±å“è¿”å›è§£æç»“æœ
        print(f"âš ï¸ æ•°æ®åº“å­˜å‚¨å¤±è´¥: {e}")

    # --- 7. è¿”å›ç»“æœ ---
    try:
        intelligence = json.loads(parsed_json_str)
    except (json.JSONDecodeError, TypeError):
        intelligence = {"raw_response": parsed_json_str}

    return {
        "success": True,
        "filename": filename,
        "extracted_text_length": len(extracted_text),
        "intelligence": intelligence,
    }





# â”€â”€ æ²™ç›˜æ¨æ¼” â”€â”€


@app.get("/api/sandbox/projects/{project_id}")
async def get_sandbox_data(project_id: int):
    """
    è¿”å›æŒ‡å®šé¡¹ç›®çš„æ²™ç›˜æ¨æ¼”æ•°æ®ã€‚
    ä» 4+1 æƒ…æŠ¥ä¸­èšåˆæ¨å¯¼å‡º bidAnalysis + intelSummaryã€‚
    """
    with get_db() as conn:
        cursor = conn.cursor()

        # 1. é¡¹ç›®åŸºæœ¬ä¿¡æ¯
        cursor.execute(
            "SELECT project_id, project_name, current_stage, client, applicant, dept, "
            "COALESCE(design_institute, '') AS design_institute, "
            "COALESCE(general_contractor, '') AS general_contractor "
            "FROM projects WHERE project_id = ?",
            (project_id,),
        )
        row = cursor.fetchone()
        if not row:
            return {"error": f"é¡¹ç›® ID {project_id} ä¸å­˜åœ¨", "project": None}

        project_info = {
            "id": row[0],
            "name": row[1],
            "stage": row[2] or "",
            "client": row[3] or "",
            "applicant": row[4] or "",
            "dept": row[5] or "",
            "designInstitute": row[6] or "",
            "generalContractor": row[7] or "",
        }

        # 2. å…³é”®äººæ•°é‡
        cursor.execute(
            "SELECT COUNT(*) FROM stakeholders WHERE project_id = ?",
            (project_id,),
        )
        stakeholder_count = cursor.fetchone()[0]
        project_info["stakeholderCount"] = stakeholder_count

        # 2b. å¹²ç³»äººè¯¦æƒ…åˆ—è¡¨ï¼ˆä¾›å‰ç«¯ AI å†›å¸ˆåŠ¨æ€ä¸‹æ‹‰æ¡†ï¼‰
        cursor.execute(
            "SELECT name, hard_profile, soft_persona FROM stakeholders WHERE project_id = ?",
            (project_id,),
        )
        stakeholder_rows = cursor.fetchall()
        stakeholder_list = [
            {
                "name": r["name"] or "",
                "title": r["hard_profile"] or "",
                "tags": r["soft_persona"] or "",
            }
            for r in stakeholder_rows
        ]

        # 3. æ‹‰å–è¯¥é¡¹ç›®æ‰€æœ‰ visit_logs çš„ AI è§£ææ•°æ®
        cursor.execute(
            "SELECT ai_parsed_data, created_at FROM visit_logs "
            "WHERE project_id = ? ORDER BY log_id DESC",
            (project_id,),
        )
        logs = cursor.fetchall()

    # 4. èšåˆ 4+1 æƒ…æŠ¥
    all_gap_alerts: list[str] = []
    all_competitors: list[dict] = []
    all_statuses: list[str] = []
    all_next_steps: list[str] = []
    latest_log_time = None

    for ai_json_str, created_at in logs:
        if latest_log_time is None:
            latest_log_time = created_at

        try:
            parsed = json.loads(ai_json_str) if ai_json_str else {}
        except (json.JSONDecodeError, TypeError):
            parsed = {}

        # gap_alerts
        for alert in parsed.get("gap_alerts", []):
            if alert and alert not in all_gap_alerts:
                all_gap_alerts.append(alert)

        # competitor_info
        for comp in parsed.get("competitor_info", []):
            name = comp.get("name", "").strip()
            if name and not any(c.get("name") == name for c in all_competitors):
                all_competitors.append({
                    "name": name,
                    "quote": comp.get("quote"),
                    "strengths": comp.get("strengths", ""),
                    "weaknesses": comp.get("weaknesses", ""),
                    "recentActions": comp.get("recent_actions", ""),
                })

        # current_status
        status = parsed.get("current_status", "")
        if status and status != "æœªæä¾›é¡¹ç›®ç°çŠ¶ã€é¢„ç®—ä¸è¿›åº¦ä¿¡æ¯":
            all_statuses.append(status)

        # next_steps
        ns = parsed.get("next_steps", "")
        if ns and ns != "æœªæä¾›ä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’":
            all_next_steps.append(ns)

    # 5. æ¨å¯¼æ§æ ‡ç‚¹ (control points)
    control_points: list[dict] = []

    # 5a. ä» gap_alerts æ¨å¯¼
    budget_unknown = any("æœªç¡®è®¤" in g and "é¢„ç®—" in g for g in all_gap_alerts)
    decision_unknown = any("æœªè¯†åˆ«" in g and "å†³ç­–" in g for g in all_gap_alerts)

    if budget_unknown:
        control_points.append({
            "text": "é¡¹ç›®é¢„ç®—å°šæœªç¡®è®¤ï¼ŒæŠ¥ä»·åŸºå‡†ç¼ºå¤±",
            "risk": "high",
        })
    if decision_unknown:
        control_points.append({
            "text": "å…³é”®å†³ç­–é“¾æœªå®Œæ•´è¦†ç›–ï¼Œå­˜åœ¨ç›²åŒºå†³ç­–äºº",
            "risk": "high",
        })

    # 5b. ä» stakeholder æ•°é‡æ¨å¯¼
    if stakeholder_count < 3:
        control_points.append({
            "text": f"å†³ç­–é“¾ä¿¡æ¯ä¸è¶³ï¼ˆä»…è¦†ç›– {stakeholder_count} äººï¼‰ï¼Œéœ€è¡¥é½ç»„ç»‡æ¶æ„",
            "risk": "medium",
        })

    # 5c. ä»ç«å“è¦†ç›–åº¦æ¨å¯¼
    if not all_competitors:
        control_points.append({
            "text": "æš‚æ— ç«å“æƒ…æŠ¥ï¼Œç«äº‰æ€åŠ¿ä¸æ˜ï¼Œå¯èƒ½é—æ¼å¼ºåŠ²å¯¹æ‰‹",
            "risk": "medium",
        })
    elif len(all_competitors) >= 3:
        control_points.append({
            "text": f"ç«äº‰æ¿€çƒˆï¼ˆå·²è¯†åˆ« {len(all_competitors)} å®¶å¯¹æ‰‹ï¼‰ï¼Œéœ€é‡ç‚¹é˜²å®ˆ",
            "risk": "high",
        })

    # 5d. ä»æƒ…æŠ¥è®°å½•é‡æ¨å¯¼
    if len(logs) == 0:
        control_points.append({
            "text": "è¯¥é¡¹ç›®æ— ä»»ä½•æƒ…æŠ¥è®°å½•ï¼Œæ²™ç›˜æ•°æ®ä¸ºç©ºç™½çŠ¶æ€",
            "risk": "high",
        })
    elif len(logs) < 3:
        control_points.append({
            "text": f"æƒ…æŠ¥ç§¯ç´¯ä¸è¶³ï¼ˆä»… {len(logs)} æ¡è®°å½•ï¼‰ï¼Œç ”åˆ¤ç½®ä¿¡åº¦ä½",
            "risk": "low",
        })

    # 6. æ˜ å°„åºŸæ ‡é£é™© (rejection risks)
    rejection_risks: list[dict] = []
    for alert in all_gap_alerts:
        severity = "critical" if any(kw in alert for kw in ["æœªç¡®è®¤", "æœªè¯†åˆ«", "æœªè·å–"]) else "warning"
        rejection_risks.append({
            "text": alert.replace("âš ï¸ ", ""),
            "severity": severity,
        })

    # 7. ä» current_status ä¸­å°è¯•æå–æœ€é«˜é™ä»· / é¢„ç®—
    import re
    max_price = None
    for status in all_statuses:
        # åŒ¹é…ä¸­æ–‡é‡‘é¢æ ¼å¼ï¼šæ•°å­—+ä¸‡ æˆ– æ•°å­—+äº¿
        price_match = re.search(r"(\d+(?:\.\d+)?)\s*[ä¸‡äº¿]", status)
        if price_match:
            val = float(price_match.group(1))
            unit = "äº¿" if "äº¿" in status[price_match.start():price_match.end()+1] else "ä¸‡"
            max_price = val * 10000 if unit == "äº¿" else val
            break

    # 8. ç»„è£…è¿”å›
    return {
        "project": project_info,
        "bidAnalysis": {
            "controlPoints": control_points,
            "rejectionRisks": rejection_risks,
            "maxPrice": max_price,
            "competitors": all_competitors,
        },
        "intelSummary": {
            "currentStatus": all_statuses[0] if all_statuses else "æš‚æ— é¡¹ç›®ç°çŠ¶æƒ…æŠ¥",
            "nextSteps": all_next_steps[0] if all_next_steps else "æš‚æ— ä¸‹ä¸€æ­¥è®¡åˆ’",
            "logCount": len(logs),
            "latestLogTime": latest_log_time,
        },
        "stakeholders": stakeholder_list,
    }

# â”€â”€ AI ç»Ÿå¸…éƒ¨ï¼šèµ¢ç‡è¯Šæ–­ & NBA æŠ¥å‘Š â”€â”€


# MEDDIC åŠ¨æ€èµ¢ç‡è¯„ä»·ç»´åº¦ï¼ˆåŸç‰ˆå¤åˆ»ï¼‰
_NBA_EVAL_DIMENSIONS = {
    "M â€” é‡åŒ–æŒ‡æ ‡ (Metrics)": 80,
    "E â€” ç»æµå†³ç­–è€… (Economic Buyer)": 100,
    "D â€” å†³ç­–æ ‡å‡† (Decision Criteria)": 70,
    "D â€” å†³ç­–æµç¨‹ (Decision Process)": 70,
    "I â€” æ ¸å¿ƒç—›ç‚¹ (Identify Pain)": 90,
    "C â€” å†…éƒ¨æ•™ç»ƒ (Champion)": 90,
    "R â€” åˆ©ç›Šå…³ç³»æ†ç»‘ (Relationship)": 85,
}


@app.post("/api/ai/generate_nba")
async def generate_nba(request: Request):
    """
    èµ¢ç‡è¯Šæ–­ä¸ NBA (Next Best Action) æŠ¥å‘Šç”Ÿæˆã€‚
    èšåˆè¯¥é¡¹ç›®å…¨é‡ visit_logs â†’ MEDDIC 7 ç»´åŠ æƒæ‰“åˆ† â†’ èµ¢ç‡ + ç›²åŒº + æ æ† + NBAã€‚
    """
    from llm_service import build_llm_router
    import base64

    body = await request.json()
    project_id = body.get("project_id")
    api_key = request.headers.get("X-API-Key", "").strip()

    # è§£æ LLM é…ç½®
    llm_configs: dict = {}
    llm_config_raw = request.headers.get("X-LLM-Config", "").strip()
    if llm_config_raw:
        try:
            llm_configs = json.loads(base64.b64decode(llm_config_raw).decode("utf-8"))
        except Exception:
            llm_configs = {}

    if not api_key and not llm_configs:
        return JSONResponse(content={"error": "è¯·å…ˆé…ç½® API Key"}, status_code=401)

    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT project_name FROM projects WHERE project_id = ?", (project_id,))
        proj = cursor.fetchone()
        if not proj:
            return JSONResponse(content={"error": "é¡¹ç›®ä¸å­˜åœ¨"}, status_code=404)
        project_name = proj[0]

        cursor.execute(
            "SELECT ai_parsed_data FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
            (project_id,),
        )
        logs = cursor.fetchall()

    # èšåˆæƒ…æŠ¥
    intel_parts = [str(row[0]) for row in logs if row[0]]
    current_data = "\n".join(intel_parts)
    if not current_data.strip():
        current_data = f"ã€ç³»ç»Ÿæç¤ºã€‘ï¼šé¡¹ç›® {project_name} æš‚æ— æƒ…æŠ¥è®°å½•ï¼Œè¯·åŸºäºç©ºç™½çŠ¶æ€ç»™å‡ºé€šç”¨å»ºè®®ã€‚"

    # åŠ¨æ€ç»´åº¦å­—ç¬¦ä¸²
    dim_string = "\n".join([
        f"- **{dim}** (æ¨¡å‹èµ‹äºˆé‡è¦åº¦: {weight}/100)ï¼š[è¯·æ‰“åˆ† X/10åˆ†] - ä¾æ®ï¼š[è¯·ç»“åˆæƒ…æŠ¥è¯´æ˜æ‰“åˆ†ä¾æ®]"
        for dim, weight in _NBA_EVAL_DIMENSIONS.items()
    ])

    nba_prompt = f"""ä½ æ˜¯ä¸€ä½èº«ç»ç™¾æˆ˜çš„ B2B å¤§å®¢æˆ·é”€å”®å‰¯æ€»è£ã€‚è¯·é˜…è¯»è¯¥é¡¹ç›®è‡ªç«‹é¡¹ä»¥æ¥çš„æ‰€æœ‰æƒ…æŠ¥è®°å½•ã€‚

ã€ä½ çš„ä»»åŠ¡ã€‘ï¼š
è¯·æ‘’å¼ƒä¸»è§‚ç›´è§‰ï¼Œä¸¥æ ¼æŒ‰ç…§æˆ‘æ–¹è®¾å®šçš„ã€åŠ¨æ€èµ¢ç‡è¯„ä»·æ¨¡å‹ã€‘è¾“å‡ºç»“æ„åŒ–è¯Šæ–­æŠ¥å‘Šã€‚å¿…é¡»åŒ…å«ä»¥ä¸‹å››ä¸ªéƒ¨åˆ†ï¼Œå¹¶ä¸¥æ ¼ä½¿ç”¨ Markdown æ ¼å¼ï¼š

### ğŸ“Š åŠ¨æ€å¤šç»´é›·è¾¾æµ‹ç®—
[è¯·æ ¹æ®æƒ…æŠ¥ï¼Œå¯¹ä»¥ä¸‹æˆ‘æ–¹è®¾å®šçš„æ ¸å¿ƒç»´åº¦åˆ†åˆ«è¿›è¡Œä¸¥è‹›æ‰“åˆ†ï¼ˆå•é¡¹æ»¡åˆ†10åˆ†ï¼‰ï¼š]
{dim_string}

**ğŸ“ˆ ä¸¥æ ¼æŠ˜ç®—å½“å‰çœŸå®èµ¢ç‡**ï¼š[X]%
(æ³¨ï¼šè¯·åˆ©ç”¨ä½ æ‰“å‡ºçš„å•é¡¹åˆ†æ•°ï¼Œç»“åˆæˆ‘ä»¬èµ‹äºˆè¯¥é¡¹çš„ã€é‡è¦åº¦ã€‘è¿›è¡ŒåŠ æƒå¹³å‡è®¡ç®—ï¼Œå¾—å‡ºæœ€å…·ç§‘å­¦æ€§çš„çœŸå®èµ¢ç‡ç™¾åˆ†æ¯”)

### ğŸš¨ å½“å‰è‡´å‘½ç›²åŒº (Red Flags)
[é‡ç‚¹é’ˆå¯¹ä¸Šè¿°æ‰“åˆ†åœ¨ 5 åˆ†åŠä»¥ä¸‹çš„ä½åˆ†é¡¹ï¼Œåˆ—å‡º 1 åˆ° 2 ä¸ªé”€å”®å½“å‰çš„è‡´å‘½æ¼æ´ï¼Œè¯­æ°”è¦æåº¦çŠ€åˆ©ä¸¥å‰ï¼]

### ğŸ’¡ æˆ‘æ–¹æ ¸å¿ƒæ æ†
[ç»“åˆä¸Šè¿°çš„é«˜åˆ†é¡¹ï¼ŒæŒ‡å‡ºæˆ‘ä»¬å½“å‰æœ€èƒ½æ‹¿æ¥ç¿»ç›˜æˆ–é”å®šèƒœå±€çš„æ­¦å™¨æ˜¯ä»€ä¹ˆã€‚]

### ğŸš€ ä¸‹ä¸€æ­¥æœ€ä½³è¡ŒåŠ¨ (Next Best Action)
[ç»™å‡º 3 æ¡æå…¶å…·ä½“çš„ã€é’ˆå¯¹å¼¥è¡¥ä¸Šè¿°ä½åˆ†ç›²åŒºçš„æˆ˜æœ¯åŠ¨ä½œã€‚å¿…é¡»æ˜¯é”€å”®æ˜å¤©å°±èƒ½å»æ‰§è¡Œçš„å…·ä½“äº‹é¡¹ï¼]

ä»¥ä¸‹æ˜¯è¯¥é¡¹ç›®çš„æ‰€æœ‰å†å²æƒ…æŠ¥æ¡£æ¡ˆï¼š
{current_data}
"""

    try:
        router = build_llm_router(primary_api_key=api_key, llm_configs=llm_configs)
        report = router.chat(
            messages=[{"role": "user", "content": nba_prompt}],
            temperature=0.5,
        )
        return {"report": report, "projectName": project_name}
    except Exception as e:
        return JSONResponse(content={"error": f"AI è¯Šæ–­å¤±è´¥: {str(e)}"}, status_code=500)


# â”€â”€ å¹²ç³»äººä¿å­˜ â”€â”€


@app.post("/api/sandbox/stakeholders/save")
async def save_stakeholders(request: Request):
    """
    å…¨é‡æ›¿æ¢ä¿å­˜å¹²ç³»äººæ•°æ®ã€‚
    Body: { project_id: 1, stakeholders: [{name, title, role, attitude, influence, reports_to}] }
    """
    body = await request.json()
    project_id = body.get("project_id")
    stakeholders = body.get("stakeholders", [])

    if not project_id:
        return JSONResponse(content={"error": "ç¼ºå°‘ project_id"}, status_code=400)

    with get_db() as conn:
        cursor = conn.cursor()
        # å…¨é‡æ›¿æ¢ç­–ç•¥
        cursor.execute("DELETE FROM stakeholders WHERE project_id = ?", (project_id,))
        for s in stakeholders:
            name = s.get("name", "").strip()
            if not name:
                continue
            hard_profile = s.get("title", "")
            # å°†è§’è‰² + æ€åº¦ + å½±å“åŠ› + æ±‡æŠ¥å…³ç³»åˆå¹¶ä¸º soft_persona
            role = s.get("role", "")
            attitude = s.get("attitude", "")
            influence = s.get("influence", "")
            reports_to = s.get("reports_to", "")
            soft_parts = [p for p in [role, attitude, f"å½±å“åŠ›:{influence}" if influence else "", f"æ±‡æŠ¥ç»™:{reports_to}" if reports_to else ""] if p]
            soft_persona = " | ".join(soft_parts)
            cursor.execute(
                "INSERT INTO stakeholders (name, project_id, hard_profile, soft_persona) VALUES (?, ?, ?, ?)",
                (name, project_id, hard_profile, soft_persona),
            )
        conn.commit()

    return {"saved": len([s for s in stakeholders if s.get("name", "").strip()])}

# â”€â”€ ç«åŠ›æ”¯æ´ç³»ç»Ÿ (åŸç‰ˆ app.py L1422-1737) â”€â”€


def _get_project_intel_context(project_id: int) -> str:
    """èšåˆæŒ‡å®šé¡¹ç›®çš„å…¨é‡æƒ…æŠ¥æ–‡æœ¬ï¼Œä¾› AI ç”Ÿæˆä½¿ç”¨ã€‚"""
    import sqlite3
    conn = sqlite3.connect("intel_system.db")
    cursor = conn.cursor()
    cursor.execute(
        "SELECT ai_parsed_data FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
        (project_id,),
    )
    rows = cursor.fetchall()
    conn.close()
    return "\n".join([r[0] for r in rows if r[0]])


@app.post("/api/ai/generate_followup")
async def generate_followup(request: Request):
    """ç”Ÿæˆè·Ÿè¿›è¯æœ¯ (å¾®ä¿¡/é‚®ä»¶)ã€‚"""
    body = await request.json()
    api_key = _resolve_api_key(request)
    if not api_key:
        return JSONResponse(content={"error": "æœªé…ç½® API Key"}, status_code=400)

    project_id = body.get("project_id")
    context = _get_project_intel_context(project_id) if project_id else ""

    try:
        from llm_service import generate_followup_email
        result = generate_followup_email(
            api_key=api_key,
            context_data=context or "æš‚æ— æƒ…æŠ¥æ•°æ®",
            channel=body.get("channel", "email"),
            target_person=body.get("target_person", "å…³é”®å†³ç­–äºº"),
            project_stage=body.get("project_stage", "åˆæœŸæ¥è§¦"),
            use_top_to_top=body.get("use_top_to_top", False),
            shared_history=body.get("shared_history", ""),
            is_director=body.get("is_director", False),
            subordinate_name=body.get("subordinate_name", ""),
        )
        return {"success": True, "content": result}
    except Exception as e:
        return JSONResponse(content={"error": f"ç”Ÿæˆå¤±è´¥: {str(e)}"}, status_code=500)


@app.post("/api/ai/generate_tech_summary")
async def generate_tech_summary_endpoint(request: Request):
    """ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆæ‘˜è¦ã€‚"""
    body = await request.json()
    api_key = _resolve_api_key(request)
    if not api_key:
        return JSONResponse(content={"error": "æœªé…ç½® API Key"}, status_code=400)

    project_id = body.get("project_id")
    context = _get_project_intel_context(project_id) if project_id else ""

    try:
        from llm_service import generate_tech_summary
        result = generate_tech_summary(
            api_key=api_key,
            context_data=context or "æš‚æ— æƒ…æŠ¥æ•°æ®",
            channel=body.get("channel", "email"),
            tech_competitor=body.get("tech_competitor", ""),
            tech_status=body.get("tech_status", ""),
            tech_pain_points=body.get("tech_pain_points", []),
            tech_role=body.get("tech_role", []),
        )
        return {"success": True, "content": result}
    except Exception as e:
        return JSONResponse(content={"error": f"ç”Ÿæˆå¤±è´¥: {str(e)}"}, status_code=500)


@app.post("/api/ai/generate_insider_ammo")
async def generate_insider_ammo_endpoint(request: Request):
    """ç”Ÿæˆå†…çº¿è¯æœ¯ (3 ç‰ˆæœ¬)ã€‚"""
    body = await request.json()
    api_key = _resolve_api_key(request)
    if not api_key:
        return JSONResponse(content={"error": "æœªé…ç½® API Key"}, status_code=400)

    project_id = body.get("project_id")
    context = _get_project_intel_context(project_id) if project_id else ""

    try:
        from llm_service import generate_insider_ammo
        result = generate_insider_ammo(
            api_key=api_key,
            context_data=context or "æš‚æ— æƒ…æŠ¥æ•°æ®",
            channel=body.get("channel", "wechat"),
            target_person=body.get("target_person", "æ•™ç»ƒ/å†…çº¿"),
            project_stage=body.get("project_stage", "åˆæœŸæ¥è§¦"),
            leader_attitude=body.get("leader_attitude", ""),
            leader_history=body.get("leader_history", ""),
        )
        return {"success": True, "content": result}
    except Exception as e:
        return JSONResponse(content={"error": f"ç”Ÿæˆå¤±è´¥: {str(e)}"}, status_code=500)

# â”€â”€ AI å‚è°‹éƒ¨èŠå¤© (åŸç‰ˆ app.py L1741-1791) â”€â”€


@app.post("/api/ai/chat")
async def ai_chat(request: Request):
    """AI å‚è°‹éƒ¨ï¼šå¸¦é¡¹ç›®ä¸Šä¸‹æ–‡çš„å¯¹è¯å¼é—®ç­”ã€‚"""
    body = await request.json()
    api_key = _resolve_api_key(request)
    if not api_key:
        return JSONResponse(content={"error": "æœªé…ç½® API Key"}, status_code=400)

    project_id = body.get("project_id")
    messages = body.get("messages", [])
    user_query = messages[-1]["content"] if messages else ""

    if not user_query.strip():
        return JSONResponse(content={"error": "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜"}, status_code=400)

    context = _get_project_intel_context(project_id) if project_id else ""

    try:
        from llm_service import chat_with_project
        result = chat_with_project(
            api_key=api_key,
            context_data=context or "æš‚æ— æƒ…æŠ¥æ•°æ®",
            user_query=user_query,
        )
        return {"success": True, "content": result}
    except Exception as e:
        return JSONResponse(content={"error": f"å‚è°‹éƒ¨é€šä¿¡æ•…éšœ: {str(e)}"}, status_code=500)

# â”€â”€ AI ä¼´å­¦ä¸­å¿ƒ (åŸç‰ˆ app.py L1794-1922) â”€â”€


@app.post("/api/ai/generate_quiz")
async def generate_quiz_endpoint(request: Request):
    """åŸºäºé¡¹ç›®æƒ…æŠ¥ç”Ÿæˆå®æˆ˜æµ‹éªŒé¢˜ã€‚"""
    body = await request.json()
    api_key = _resolve_api_key(request)
    if not api_key:
        return JSONResponse(content={"error": "æœªé…ç½® API Key"}, status_code=400)

    project_id = body.get("project_id")
    context = _get_project_intel_context(project_id) if project_id else ""

    try:
        from llm_service import generate_quiz
        quiz = generate_quiz(api_key=api_key, context_data=context or "æš‚æ— æƒ…æŠ¥æ•°æ®")
        return {"success": True, "quiz": quiz}
    except Exception as e:
        return JSONResponse(content={"error": f"å‡ºé¢˜å¤±è´¥: {str(e)}"}, status_code=500)


@app.post("/api/ai/coach_evaluate")
async def coach_evaluate(request: Request):
    """AIé”€å”®æ•™å¤´ç‚¹è¯„ç”¨æˆ·çš„å®æˆ˜åº”å¯¹è¯æœ¯ã€‚"""
    body = await request.json()
    api_key = _resolve_api_key(request)
    if not api_key:
        return JSONResponse(content={"error": "æœªé…ç½® API Key"}, status_code=400)

    project_id = body.get("project_id")
    quiz_question = body.get("quiz", "")
    user_answer = body.get("answer", "")
    if not user_answer.strip():
        return JSONResponse(content={"error": "è¯·å…ˆè¾“å…¥æ‚¨çš„åº”å¯¹è¯æœ¯"}, status_code=400)

    context = _get_project_intel_context(project_id) if project_id else "æš‚æ— æƒ…æŠ¥"

    coach_prompt = f"""ä½ æ˜¯ä¸€ä½å¹´è–ªåƒä¸‡çš„ B2B å¤§å®¢æˆ·é”€å”®æ€»ç›‘å…¼æ— æƒ…çš„æ¼”ç»ƒæ•™å¤´ï¼ˆç²¾é€š Miller Heiman ä½“ç³»ï¼‰ã€‚

ã€é¡¹ç›®å½“å‰å±€åŠ¿ä¸åŸºåº§æƒ…æŠ¥ã€‘ï¼š
{context}

ã€AI æ•™ç»ƒå‡ºçš„å®æˆ˜é¢˜ã€‘ï¼š
{quiz_question}

ã€é”€å”®å‘˜çš„å®æˆ˜è¯æœ¯/ç­–ç•¥ã€‘ï¼š
"{user_answer}"

ã€ä½ çš„ç‚¹è¯„ä»»åŠ¡ã€‘ï¼š
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼š

### ğŸ“Š æˆ˜æœ¯ç»´åº¦è¯„åˆ† (æ€»åˆ† 100)
- **ç ´å†°ä¸å…±æƒ… (25åˆ†)**ï¼š[æ‰“åˆ†] - [ç‚¹è¯„]
- **ç—›ç‚¹ä¸ä»·å€¼ (25åˆ†)**ï¼š[æ‰“åˆ†] - [ç‚¹è¯„]
- **æ’ä»–ä¸æ§æ ‡ (25åˆ†)**ï¼š[æ‰“åˆ†] - [ç‚¹è¯„]
- **æ¨è¿›ä¸é€¼å• (25åˆ†)**ï¼š[æ‰“åˆ†] - [ç‚¹è¯„]

### ğŸ”ª è‡´å‘½æ¼æ´å‰–æ
[æŒ‡å‡ºè¯æœ¯ä¸­æœ€è‡´å‘½çš„1-2ä¸ªæ¼æ´]

### ğŸ’ æ»¡åˆ†ç¤ºèŒƒ (æ•™å¤´ä¸‹åœºæ¼”ç¤º)
[å†™ä¸€æ®µå¯ä»¥ç›´æ¥å‘é€çš„æ»¡åˆ†è¯æœ¯]"""

    try:
        from openai import OpenAI as _OpenAI
        _client = _OpenAI(api_key=api_key)
        response = _client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æå…¶ä¸¥è‹›çš„ B2B å¤§å®¢æˆ·é”€å”®æ•™å¤´ã€‚"},
                {"role": "user", "content": coach_prompt},
            ],
            temperature=0.7,
        )
        feedback = response.choices[0].message.content
        return {"success": True, "feedback": feedback}
    except Exception as e:
        return JSONResponse(content={"error": f"ç‚¹è¯„å¼•æ“æ•…éšœ: {str(e)}"}, status_code=500)


# â”€â”€ æƒåŠ›åœ°å›¾å…³ç³»å›¾è°±ç”Ÿæˆ â”€â”€


@app.post("/api/ai/generate_power_map")
async def generate_power_map(request: Request):
    """
    ç”Ÿæˆ Mermaid å…³ç³»å›¾è°± + å®šç‚¹çˆ†ç ´ç­–ç•¥ã€‚
    Body: { project_id, project_name, stakeholders_csv }
    """
    from llm_service import build_llm_router
    import base64

    body = await request.json()
    project_name = body.get("project_name", "")
    stakeholders_csv = body.get("stakeholders_csv", "")
    api_key = request.headers.get("X-API-Key", "").strip()

    llm_configs: dict = {}
    llm_config_raw = request.headers.get("X-LLM-Config", "").strip()
    if llm_config_raw:
        try:
            llm_configs = json.loads(base64.b64decode(llm_config_raw).decode("utf-8"))
        except Exception:
            llm_configs = {}

    if not api_key and not llm_configs:
        return JSONResponse(content={"error": "è¯·å…ˆé…ç½® API Key"}, status_code=401)

    if not stakeholders_csv.strip():
        return JSONResponse(content={"error": "å¹²ç³»äººæ•°æ®ä¸ºç©º"}, status_code=400)

    power_prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­å›½å¼å…³ç³»é”€å”®çš„å†›å¸ˆã€‚è¿™æ˜¯é¡¹ç›®ã€{project_name}ã€‘çš„å…³é”®äººç‰©ï¼š
{stakeholders_csv}

è¯·è¾“å‡ºï¼š
### 1. ğŸ•¸ï¸ æƒåŠ›å…³ç³»å›¾è°± (Mermaid)
è¯·ç”Ÿæˆä¸€æ®µ Mermaid `graph TD` ä»£ç ï¼Œç›´è§‚å±•ç¤ºæ±‡æŠ¥å…³ç³»ã€‚é“æ†æ”¯æŒè€…ç”¨ç»¿è‰²èŠ‚ç‚¹(style X fill:#4ade80)ã€‚æ­»æ•Œç”¨çº¢è‰²èŠ‚ç‚¹(style X fill:#f87171)ã€‚ä¸­ç«‹ç”¨é»„è‰²(style X fill:#facc15)ã€‚

### 2. ğŸ’£ å®šç‚¹çˆ†ç ´ä¸é˜²å¾¡ç­–ç•¥
ç»™å‡º 3 æ¡æå…¶å…·ä½“çš„ç ´å±€æˆ˜æœ¯ã€‚
"""

    try:
        router = build_llm_router(primary_api_key=api_key, llm_configs=llm_configs)
        analysis = router.chat(
            messages=[{"role": "user", "content": power_prompt}],
            temperature=0.6,
        )

        # å°è¯•æå– Mermaid ä»£ç å—
        import re
        mermaid_match = re.search(r'```mermaid(.*?)```', analysis, re.DOTALL)
        mermaid_code = mermaid_match.group(1).strip() if mermaid_match else ""
        strategy = re.sub(r'```mermaid.*?```', '', analysis, flags=re.DOTALL).strip()

        return {"mermaid": mermaid_code, "strategy": strategy, "raw": analysis}
    except Exception as e:
        return JSONResponse(content={"error": f"AI æ¨æ¼”å¤±è´¥: {str(e)}"}, status_code=500)

# â”€â”€ AI é¹°çœ¼ï¼šä»å†å²æƒ…æŠ¥ä¸­æå–å¹²ç³»äºº â”€â”€


_EXTRACT_ROLE_OPTIONS = [
    "å†³ç­–è€… (å…³æ³¨ROI/é£é™©)",
    "ä½¿ç”¨è€… (å…³æ³¨æ˜“ç”¨/å…ç»´æŠ¤)",
    "å½±å“è€… (å…³æ³¨å‚æ•°/åˆè§„)",
    "æ•™ç»ƒ/å†…çº¿ (å…³æ³¨æ§æ ‡/æ±‡æŠ¥)",
    "æŠ€æœ¯æŠŠå…³è€… (å…³æ³¨æŠ€æœ¯æŒ‡æ ‡)",
]


@app.post("/api/ai/extract_stakeholders")
async def extract_stakeholders(request: Request):
    """
    AI é¹°çœ¼æå–ï¼šä»é¡¹ç›®å†å²æƒ…æŠ¥ä¸­è‡ªåŠ¨æå–å…³é”®å¹²ç³»äººã€‚
    èšåˆ visit_logs â†’ LLM å¼ºåˆ¶ JSON â†’ è¿”å› people[]ã€‚
    """
    from llm_service import build_llm_router
    import base64
    import re

    body = await request.json()
    project_id = body.get("project_id")
    api_key = request.headers.get("X-API-Key", "").strip()

    llm_configs: dict = {}
    llm_config_raw = request.headers.get("X-LLM-Config", "").strip()
    if llm_config_raw:
        try:
            llm_configs = json.loads(base64.b64decode(llm_config_raw).decode("utf-8"))
        except Exception:
            llm_configs = {}

    if not api_key and not llm_configs:
        return JSONResponse(content={"error": "è¯·å…ˆé…ç½® API Key"}, status_code=401)

    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT project_name FROM projects WHERE project_id = ?", (project_id,))
        proj = cursor.fetchone()
        if not proj:
            return JSONResponse(content={"error": "é¡¹ç›®ä¸å­˜åœ¨"}, status_code=404)
        project_name = proj[0]

        cursor.execute(
            "SELECT raw_input, ai_parsed_data FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
            (project_id,),
        )
        logs = cursor.fetchall()

    # èšåˆå…¨é‡æ–‡æœ¬
    full_text = ""
    for log_entry in logs:
        raw_input = str(log_entry[0]) if log_entry[0] else ""
        ai_parsed = str(log_entry[1]) if log_entry[1] else ""
        full_text += raw_input + "\n" + ai_parsed + "\n"

    if len(full_text.strip()) < 10:
        return JSONResponse(content={"error": "è¯¥é¡¹ç›®æƒ…æŠ¥åº“ä¸ºç©ºï¼Œè¯·å…ˆæäº¤æ‹œè®¿çºªè¦"}, status_code=400)

    role_list = "ã€".join(_EXTRACT_ROLE_OPTIONS)
    extract_prompt = f"""è¯·ä»ä»¥ä¸‹é¡¹ç›®å†å²æƒ…æŠ¥ä¸­ï¼Œæå–æ‰€æœ‰å‡ºç°çš„å…³é”®äººç‰©ã€‚å¿…é¡»è¾“å‡ºåˆæ³•JSONï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ï¼š
{{
    "people": [
        {{"name": "å¼ ä¸‰", "title": "æ€»ç»ç†", "role": "å†³ç­–è€… (å…³æ³¨ROI/é£é™©)", "attitude": "ğŸŸ¡ ä¸­ç«‹/è§‚æœ›", "influence": 8, "reports_to": ""}}
    ]
}}

è§„åˆ™ï¼š
- role å¿…é¡»ä»æ ‡å‡†åº“é€‰æ‹©ï¼š{role_list}
- attitude å¿…é¡»ä»ä»¥ä¸‹é€‰æ‹©ï¼šğŸŸ¢ é“æ†æ”¯æŒã€ğŸŸ¡ ä¸­ç«‹/è§‚æœ›ã€ğŸ”´ åå¯¹/æ­»æ•Œ
- influence ä¸º 1-10 çš„æ•´æ•°
- æƒ…æŠ¥ä¸è¶³ä»¥åˆ¤æ–­çš„å­—æ®µï¼Œå…è®¸è¾“å‡º "æœªçŸ¥"
- å¦‚æœæ— æ³•æå–ä»»ä½•äººç‰©ï¼Œè¿”å› {{"people": []}}

ä»¥ä¸‹æ˜¯é¡¹ç›®ã€{project_name}ã€‘çš„å…¨éƒ¨å†å²æƒ…æŠ¥ï¼š
{full_text}
"""

    try:
        router = build_llm_router(primary_api_key=api_key, llm_configs=llm_configs)
        result = router.chat(
            messages=[{"role": "user", "content": extract_prompt}],
            temperature=0.3,
        )

        # å‰¥ç¦» markdown ä»£ç å—åŒ…è£¹
        json_str = result.strip()
        if json_str.startswith("```"):
            json_str = re.sub(r'^```json|^```|```$', '', json_str, flags=re.MULTILINE).strip()

        extracted = json.loads(json_str)
        people = extracted.get("people", [])

        return {"stakeholders": people, "projectName": project_name}
    except json.JSONDecodeError as e:
        return JSONResponse(content={"error": f"AI è¿”å›æ ¼å¼å¼‚å¸¸: {str(e)}"}, status_code=500)
    except Exception as e:
        return JSONResponse(content={"error": f"AI æå–å¤±è´¥: {str(e)}"}, status_code=500)


# â”€â”€ çŸ¥è¯†åº“ â”€â”€


@app.get("/api/kb/documents")
async def get_kb_documents(category: str = "", search: str = ""):
    """
    è¿”å›çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨ã€‚
    - category: æŒ‰åˆ†ç±»ç­›é€‰ï¼ˆäº§å“å‚æ•°/ç«å“æ‰“å•å¡/å†å²ä¸­æ ‡åº“/èµ„è´¨æ–‡ä»¶ï¼‰
    - search: æ¨¡ç³Šæœç´¢ title + description
    """
    with get_db() as conn:
        cursor = conn.cursor()

        sql = "SELECT doc_id, title, category, icon, file_type, file_size, description, updated_at FROM knowledge_base"
        conditions: list[str] = []
        params: list[str] = []

        if category:
            conditions.append("category = ?")
            params.append(category)

        if search:
            conditions.append("(title LIKE ? OR description LIKE ?)")
            params.extend([f"%{search}%", f"%{search}%"])

        if conditions:
            sql += " WHERE " + " AND ".join(conditions)

        sql += " ORDER BY updated_at DESC"

        cursor.execute(sql, params)
        rows = cursor.fetchall()

    docs = []
    for row in rows:
        docs.append({
            "id": row[0],
            "title": row[1],
            "category": row[2],
            "icon": row[3],
            "fileType": row[4],
            "size": row[5],
            "description": row[6],
            "updatedAt": _format_timestamp(row[7]),
        })

    return docs


# â”€â”€ AI è¯æœ¯ç”Ÿæˆ â”€â”€


@app.post("/api/ai/generate_pitch")
async def generate_pitch(request: Request):
    """
    åŸºäºæ²™ç›˜çœŸå®æƒ…æŠ¥ï¼ŒåŠ¨æ€ç”Ÿæˆå®æˆ˜è¯æœ¯ã€‚
    Body: {"project_id": 1, "pitch_type": "wechat_msg"}
    Header: X-API-Key: sk-xxx
    """
    from llm_service import generate_sales_pitch

    # 1. è§£æè¯·æ±‚
    body = await request.json()
    project_id = body.get("project_id")
    pitch_type = body.get("pitch_type", "wechat_msg")
    target_role = body.get("target_role", "")        # å†³ç­–è€…|ä½¿ç”¨è€…|å½±å“è€…|æ•™ç»ƒ/å†…çº¿
    custom_input = body.get("custom_input", "")      # é”€å”®å‰çº¿æœ€æ–°æƒ…æŠ¥
    project_stage = body.get("project_stage", "")    # é¡¹ç›®é˜¶æ®µ
    use_history = body.get("use_history", False)      # è°ƒå–å†å²ä»·å€¼
    competitor = body.get("competitor", "")            # æ˜ç¡®å¯¹æ¯”å‹å•†
    current_status_input = body.get("current_status", "")  # å®¢æˆ·å½“å‰ç³»ç»Ÿç°çŠ¶
    pain_points = body.get("pain_points", "")         # å®¢æˆ·æ ¸å¿ƒç—›ç‚¹
    api_key = request.headers.get("X-API-Key", "").strip()

    # è§£æå‰ç«¯åŠ¨æ€ LLM è·¯ç”±é…ç½®ï¼ˆBase64 JSONï¼‰
    llm_configs: dict = {}
    llm_config_raw = request.headers.get("X-LLM-Config", "").strip()
    if llm_config_raw:
        try:
            import base64
            llm_configs = json.loads(base64.b64decode(llm_config_raw).decode("utf-8"))
        except Exception:
            llm_configs = {}  # è§£æå¤±è´¥ï¼Œé™çº§ä¸ºå• Key æ¨¡å¼

    if not api_key and not llm_configs:
        return JSONResponse(content={"error": "è¯·åœ¨ç³»ç»Ÿè®¾ç½®ä¸­é…ç½® API Keyï¼ˆHeader: X-API-Keyï¼‰"}, status_code=401)

    if pitch_type not in ("wechat_msg", "email", "internal_strategy", "tech_solution"):
        return JSONResponse(content={"error": f"ä¸æ”¯æŒçš„ pitch_type: {pitch_type}"}, status_code=400)

    # 2. ä» DB èšåˆæ²™ç›˜æƒ…æŠ¥ï¼ˆå¤ç”¨ sandbox é€»è¾‘ï¼‰
    with get_db() as conn:
        cursor = conn.cursor()

        # é¡¹ç›®åŸºæœ¬ä¿¡æ¯
        cursor.execute(
            "SELECT project_id, project_name, current_stage, client, applicant, dept FROM projects WHERE project_id = ?",
            (project_id,),
        )
        proj = cursor.fetchone()
        if not proj:
            return JSONResponse(content={"error": f"é¡¹ç›® ID {project_id} ä¸å­˜åœ¨"}, status_code=404)

        project_name = proj["project_name"]
        project_stage = proj["current_stage"]
        project_client = proj["client"] or "æœªçŸ¥å®¢æˆ·"

        # å…³é”®äººæ•°é‡
        cursor.execute("SELECT COUNT(*) as cnt FROM stakeholders WHERE project_id = ?", (project_id,))
        stakeholder_count = cursor.fetchone()["cnt"]

        # æ‹œè®¿æ—¥å¿—
        cursor.execute(
            "SELECT raw_input, ai_parsed_data, created_at FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
            (project_id,),
        )
        logs = cursor.fetchall()

    # 3. èšåˆæƒ…æŠ¥ç»´åº¦
    import re
    all_gap_alerts: list[str] = []
    all_competitors: list[dict] = []
    all_statuses: list[str] = []
    all_next_steps: list[str] = []
    latest_raw_log = ""

    for i, log in enumerate(logs):
        if i == 0 and log["raw_input"]:
            latest_raw_log = log["raw_input"][:500]

        try:
            parsed = json.loads(log["ai_parsed_data"]) if log["ai_parsed_data"] else {}
        except (json.JSONDecodeError, TypeError):
            continue

        for alert in parsed.get("gap_alerts", []):
            if alert and alert not in all_gap_alerts:
                all_gap_alerts.append(alert)

        for comp in parsed.get("competitor_info", []):
            name = comp.get("name", "")
            if name and not any(c.get("name") == name for c in all_competitors):
                all_competitors.append({
                    "name": name,
                    "quote": comp.get("quote"),
                    "strengths": comp.get("strengths", ""),
                    "weaknesses": comp.get("weaknesses", ""),
                })

        status = parsed.get("current_status", "")
        if status and status not in all_statuses:
            all_statuses.append(status)

        ns = parsed.get("next_steps", "")
        if ns and ns not in all_next_steps:
            all_next_steps.append(ns)

    # æ¨å¯¼æ§æ ‡ç‚¹
    control_points: list[str] = []
    if any("æœªç¡®è®¤" in g and "é¢„ç®—" in g for g in all_gap_alerts):
        control_points.append("é¡¹ç›®é¢„ç®—å°šæœªç¡®è®¤ï¼ŒæŠ¥ä»·åŸºå‡†ç¼ºå¤±")
    if any("æœªè¯†åˆ«" in g and "å†³ç­–" in g for g in all_gap_alerts):
        control_points.append("å…³é”®å†³ç­–é“¾æœªå®Œæ•´è¦†ç›–ï¼Œå­˜åœ¨ç›²åŒºå†³ç­–äºº")
    if stakeholder_count < 3:
        control_points.append(f"å†³ç­–é“¾ä¿¡æ¯ä¸è¶³ï¼ˆä»…è¦†ç›– {stakeholder_count} äººï¼‰")
    if not all_competitors:
        control_points.append("æš‚æ— ç«å“æƒ…æŠ¥ï¼Œç«äº‰æ€åŠ¿ä¸æ˜")

    # æå–é™ä»·
    max_price_str = "æœªæ£€æµ‹åˆ°"
    for status in all_statuses:
        price_match = re.search(r"(\d+(?:\.\d+)?)\s*[ä¸‡äº¿]", status)
        if price_match:
            val = price_match.group(0)
            max_price_str = val
            break

    # 4. åºåˆ—åŒ–ä¸º context_data æ–‡æœ¬ï¼ˆå…¨é‡æ³¨å…¥ï¼‰
    context_lines = [
        f"ã€é¡¹ç›®åç§°ã€‘{project_name}",
        f"ã€å®¢æˆ·ã€‘{project_client}",
        f"ã€é¡¹ç›®é˜¶æ®µã€‘{project_stage}",
        f"ã€å…³é”®äººè¦†ç›–ã€‘{stakeholder_count} äºº",
        f"ã€æƒ…æŠ¥è®°å½•ã€‘{len(logs)} æ¡æ‹œè®¿æ—¥å¿—",
        f"ã€é¢„ä¼°é‡‘é¢/æœ€é«˜é™ä»·ã€‘{max_price_str}",
        "",
        "ã€ç¡¬æ€§æ§æ ‡ç‚¹ã€‘",
    ]
    if control_points:
        for cp in control_points:
            context_lines.append(f"  â€¢ {cp}")
    else:
        context_lines.append("  ï¼ˆæš‚æ— ï¼‰")

    context_lines.append("")
    context_lines.append("ã€åºŸæ ‡é£é™© / æƒ…æŠ¥ç›²åŒºã€‘")
    if all_gap_alerts:
        for alert in all_gap_alerts:
            context_lines.append(f"  â€¢ {alert.replace('âš ï¸ ', '')}")
    else:
        context_lines.append("  ï¼ˆæš‚æ— ï¼‰")

    context_lines.append("")
    context_lines.append("ã€ç«å“æƒ…æŠ¥ã€‘")
    if all_competitors:
        for comp in all_competitors:
            line = f"  â€¢ {comp['name']}"
            if comp.get("quote"):
                line += f"ï¼ˆæŠ¥ä»·: {comp['quote']}ï¼‰"
            if comp.get("strengths"):
                line += f" ä¼˜åŠ¿: {comp['strengths']}"
            if comp.get("weaknesses"):
                line += f" å¼±ç‚¹: {comp['weaknesses']}"
            context_lines.append(line)
    else:
        context_lines.append("  ï¼ˆæš‚æ— ç«å“æƒ…æŠ¥ï¼‰")

    context_lines.append("")
    context_lines.append("ã€é¡¹ç›®ç°çŠ¶ã€‘")
    context_lines.append(all_statuses[0] if all_statuses else "æš‚æ— ç°çŠ¶æƒ…æŠ¥")

    context_lines.append("")
    context_lines.append("ã€ä¸‹ä¸€æ­¥è®¡åˆ’ã€‘")
    context_lines.append(all_next_steps[0] if all_next_steps else "æš‚æ— ä¸‹ä¸€æ­¥è®¡åˆ’")

    if latest_raw_log:
        context_lines.append("")
        context_lines.append("ã€æœ€æ–°ä¸€æ¡æ‹œè®¿åŸæ–‡ï¼ˆæˆªå–ï¼‰ã€‘")
        context_lines.append(latest_raw_log)

    # â”€â”€ ç»å¯¹ä¼˜å…ˆçº§é“¾æ³¨å…¥ï¼ˆä»ä½åˆ°é«˜ï¼Œæœ€åçš„ LLM æœ€å…³æ³¨ï¼‰ â”€â”€

    # ç¬¬å…­é¡ºä½ï¼šé¡¹ç›®é˜¶æ®µ
    if project_stage:
        context_lines.append(f"\nã€ğŸ“Š å½“å‰é¡¹ç›®é˜¶æ®µã€‘{project_stage}")

    # ç¬¬äº”é¡ºä½ï¼šå®¢æˆ·ç³»ç»Ÿç°çŠ¶
    if current_status_input:
        context_lines.append(f"\nã€ğŸ­ å®¢æˆ·å½“å‰ç³»ç»Ÿç°çŠ¶ã€‘{current_status_input}")

    # ç¬¬å››é¡ºä½ï¼šæ ¸å¿ƒç—›ç‚¹
    if pain_points:
        context_lines.append(f"\nã€ğŸ”¥ å®¢æˆ·æ ¸å¿ƒç—›ç‚¹ã€‘{pain_points}")
        context_lines.append("â–¶ æ‰€æœ‰è¯æœ¯å¿…é¡»æˆ®ä¸­æ­¤ç—›ç‚¹ï¼")

    # ç¬¬ä¸‰é¡ºä½ï¼šç«å“å¯¹æ ‡
    if competitor:
        context_lines.append(f"\nã€âš”ï¸ æ˜ç¡®å¯¹æ ‡ç«å“ã€‘{competitor}")
        context_lines.append("â–¶ è¯æœ¯ä¸­å¿…é¡»æš—è—é’ˆå¯¹æ€§æ‰“å‹/å¯¹æ¯”ï¼Œä½†ä¸ç›´æ¥ç‚¹åæ”»å‡»ï¼")

    # ç¬¬äºŒé¡ºä½ï¼šå†å²ä»·å€¼
    if use_history:
        context_lines.append("\nã€ğŸ•°ï¸ å†å²ä»·å€¼æŒ‡ä»¤ã€‘")
        context_lines.append("â–¶ å¿…é¡»æåŠè¿‡å¾€åˆä½œæ¸Šæºã€é«˜å±‚èµ„æºã€å†å²é¡¹ç›®äº¤é›†ï¼Œå¼ºåŒ–ä¿¡ä»»çº½å¸¦ï¼")

    # ç¬¬ä¸€é¡ºä½ï¼štarget_roleï¼ˆæ”¯æŒå¤åˆäººç‰©å­—ç¬¦ä¸²ï¼‰
    if target_role:
        if "|" in target_role:
            parts = target_role.split("|", 2)
            person_name = parts[0].strip()
            person_title = parts[1].strip() if len(parts) > 1 else ""
            role_tag = parts[2].strip() if len(parts) > 2 else ""

            context_lines.append(f"\nã€ğŸ¯ ç²¾å‡†ç‹™å‡»ç›®æ ‡ã€‘")
            context_lines.append(f"å§“å: {person_name}")
            context_lines.append(f"èŒåŠ¡: {person_title}")
            if role_tag:
                context_lines.append(f"æ€åº¦/æ ‡ç­¾: {role_tag}")
            context_lines.append(f"â–¶ ç§°è°“æŒ‡ä»¤ï¼šæ ¹æ®èŒåŠ¡è‡ªåŠ¨ç”ŸæˆèŒåœºç§°è°“ï¼ˆå¦‚'{person_name[0]}æ€»'æˆ–'{person_name[0]}å·¥'ï¼‰")
            context_lines.append(f"â–¶ å¿…é¡»å›´ç»•æ­¤äººçš„ã€èŒåŠ¡èŒè´£ã€‘å’Œã€æ€åº¦å€¾å‘ã€‘å®šåˆ¶è¯æœ¯ï¼")

            # æ€åº¦è”åŠ¨æˆ˜æœ¯ç‰µå¼•
            if "åå¯¹" in role_tag:
                context_lines.append("âš ï¸ æ­¤äººå½“å‰ã€åå¯¹ã€‘æˆ‘æ–¹ï¼è¯æœ¯å¿…é¡»ä»¥åŒ–è§£æŠµè§¦ä¸ºæ ¸å¿ƒï¼")
            elif "ä¸­ç«‹" in role_tag:
                context_lines.append("ğŸ’¡ æ­¤äººå½“å‰ã€ä¸­ç«‹è§‚æœ›ã€‘ï¼Œè¯æœ¯åº”ä¾§é‡åˆ©ç›Šå¼•å¯¼å’Œé£é™©æç¤ºã€‚")
            elif "æ”¯æŒ" in role_tag:
                context_lines.append("âœ… æ­¤äººæ˜¯æˆ‘æ–¹ã€æ”¯æŒè€…ã€‘ï¼Œè¯æœ¯åº”æä¾›å¼¹è¯è®©ä»–å†…éƒ¨æ¨åŠ¨ã€‚")
        else:
            context_lines.append(f"\nã€ğŸ¯ ç›®æ ‡è§’è‰²ã€‘{target_role}")

    # ç¬¬é›¶é¡ºä½ï¼šcustom_inputï¼ˆç»å¯¹æœ€é«˜ä¼˜å…ˆçº§ï¼Œæ”¾æœ€åç¡®ä¿ LLM æœ€å…³æ³¨ï¼‰
    if custom_input:
        context_lines.append("\nã€âš¡ é”€å”®å‰çº¿æœ€æ–°æƒ…æŠ¥ â€” ç¬¬ä¸€ä¼˜å…ˆçº§ã€‘")
        context_lines.append(custom_input)
        context_lines.append("âš ï¸ æ­¤æƒ…æŠ¥åˆšè·å–ï¼Œæ‰€æœ‰è¯æœ¯å¿…é¡»æ— æ¡ä»¶ç´§æ‰£æ­¤ä¿¡æ¯å±•å¼€ï¼")

    context_data = "\n".join(context_lines)

    # 5. è°ƒç”¨ LLM
    try:
        pitch_text = generate_sales_pitch(
            api_key=api_key,
            context_data=context_data,
            pitch_type=pitch_type,
            target_role=target_role,
            llm_configs=llm_configs,
        )
        return {
            "pitch": pitch_text,
            "pitchType": pitch_type,
            "projectName": project_name,
        }
    except Exception as e:
        return JSONResponse(content={"error": f"AI ç”Ÿæˆå¤±è´¥: {str(e)}"}, status_code=500)



if __name__ == "__main__":
    import uvicorn

    uvicorn.run("api:app", host="0.0.0.0", port=8000, reload=True)
