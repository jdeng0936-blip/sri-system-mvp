import sqlite3


def init_db():
    """åˆå§‹åŒ– SRI æƒ…æŠ¥ç³»ç»Ÿæ•°æ®åº“ï¼Œåˆ›å»ºæ ¸å¿ƒè¡¨ç»“æ„ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()

    # é¡¹ç›®è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS projects (
            project_id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_name TEXT,
            current_stage TEXT,
            tech_specs TEXT,
            war_gaming_tags TEXT
        )
    """)

    # å¹²ç³»äººè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS stakeholders (
            person_id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT,
            project_id INTEGER,
            hard_profile TEXT,
            soft_persona TEXT
        )
    """)

    # æ‹œè®¿æ—¥å¿—è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS visit_logs (
            log_id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            raw_input TEXT,
            ai_parsed_data TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # â”€â”€ å…¼å®¹å‡çº§ï¼šä¸ºæ—§è¡¨è¡¥å…… created_at åˆ— â”€â”€
    cursor.execute("PRAGMA table_info(visit_logs)")
    columns = [row[1] for row in cursor.fetchall()]
    if "created_at" not in columns:
        cursor.execute(
            "ALTER TABLE visit_logs ADD COLUMN created_at TIMESTAMP"
        )

    # æµ‹éªŒè®°å½•è¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS test_records (
            record_id INTEGER PRIMARY KEY AUTOINCREMENT,
            user TEXT DEFAULT 'default',
            project_id INTEGER,
            quiz TEXT,
            user_answer TEXT,
            score INTEGER,
            critique TEXT,
            blind_spots TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    conn.commit()

    # â”€â”€ Entity-First æ¶æ„å‡çº§ï¼šä¸º projects è¡¨è¿½åŠ å®ä½“å­—æ®µ â”€â”€
    cursor.execute("PRAGMA table_info(projects)")
    existing_cols = {row[1] for row in cursor.fetchall()}
    entity_columns = {
        "client": "TEXT DEFAULT ''",
        "design_institute": "TEXT DEFAULT ''",
        "general_contractor": "TEXT DEFAULT ''",
        "applicant": "TEXT DEFAULT ''",
        "dept": "TEXT DEFAULT ''",
    }
    for col_name, col_type in entity_columns.items():
        if col_name not in existing_cols:
            cursor.execute(f"ALTER TABLE projects ADD COLUMN {col_name} {col_type}")
    conn.commit()

    # â”€â”€ çŸ¥è¯†åº“è¡¨ â”€â”€
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS knowledge_base (
            doc_id      INTEGER PRIMARY KEY AUTOINCREMENT,
            title       TEXT NOT NULL,
            category    TEXT NOT NULL,
            icon        TEXT DEFAULT 'ğŸ“„',
            file_type   TEXT DEFAULT 'PDF',
            file_size   TEXT DEFAULT '',
            description TEXT DEFAULT '',
            file_path   TEXT DEFAULT '',
            created_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at  TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()

    # â”€â”€ ç§å­æ•°æ®ï¼ˆå¹‚ç­‰ï¼šä»…ç©ºè¡¨æ—¶æ’å…¥ï¼‰â”€â”€
    cursor.execute("SELECT COUNT(*) FROM knowledge_base")
    if cursor.fetchone()[0] == 0:
        seed_docs = [
            ("æš–é€šç©ºè°ƒäº§å“é€‰å‹æ‰‹å†Œ v3.2", "äº§å“å‚æ•°", "ğŸ“„", "PDF", "12.4 MB",
             "å…¨ç³»åˆ—äº§å“æŠ€æœ¯å‚æ•°ã€é€‰å‹å…¬å¼ä¸å®‰è£…è§„èŒƒ"),
            ("ä¸­å¤®ç©ºè°ƒèƒ½æ•ˆå¯¹æ ‡è¡¨", "äº§å“å‚æ•°", "ğŸ“Š", "XLSX", "3.8 MB",
             "COP/EER èƒ½æ•ˆç­‰çº§å…¨å“ç‰Œæ¨ªå‘å¯¹æ¯”"),
            ("å˜é¢‘å¤šè”æœºæŠ€æœ¯ç™½çš®ä¹¦", "äº§å“å‚æ•°", "ğŸ“‘", "PDF", "7.6 MB",
             "æ–°ä¸€ä»£å˜é¢‘æŠ€æœ¯åŸç†ä¸èŠ‚èƒ½æ•°æ®"),
            ("æ ¼åŠ› vs ç¾çš„ ç«å“æ‰“å•å¡", "ç«å“æ‰“å•å¡", "âš”ï¸", "PDF", "5.2 MB",
             "æ ¸å¿ƒæŠ€æœ¯å·®å¼‚ã€æŠ¥ä»·ç­–ç•¥ã€å®¢æˆ·ç—›ç‚¹è¯æœ¯"),
            ("å¤§é‡‘ VRV ç³»åˆ—æ”»é˜²æ‰‹å†Œ", "ç«å“æ‰“å•å¡", "ğŸ›¡ï¸", "PDF", "4.1 MB",
             "å¤§é‡‘äº§å“å¼±ç‚¹åˆ†æåŠæˆ‘æ–¹ä¼˜åŠ¿è¯æœ¯"),
            ("æµ·å°”ç£æ‚¬æµ®ç«å“å¯¹æŠ—æŒ‡å—", "ç«å“æ‰“å•å¡", "ğŸ¯", "DOCX", "2.9 MB",
             "ç£æ‚¬æµ®æœºç»„æŠ€æœ¯å¯¹æ¯”ä¸å•†åŠ¡ç­–ç•¥"),
            ("2025å¹´åº¦ä¸­æ ‡é¡¹ç›®æ±‡ç¼–", "å†å²ä¸­æ ‡åº“", "ğŸ†", "PDF", "28.6 MB",
             "å…¨å¹´ 47 ä¸ªä¸­æ ‡é¡¹ç›®å¤ç›˜ï¼Œå«æŠ¥ä»·ä¸ä¸­æ ‡ç­–ç•¥"),
            ("åŒ»é™¢ç³»ç»Ÿä¸­æ ‡æ¡ˆä¾‹é›†", "å†å²ä¸­æ ‡åº“", "ğŸ¥", "PDF", "15.3 MB",
             "ä¸‰ç”²åŒ»é™¢æš–é€šé¡¹ç›®ä¸­æ ‡æ–¹æ¡ˆä¸ç»éªŒæ€»ç»“"),
            ("æ•°æ®ä¸­å¿ƒåˆ¶å†·ä¸­æ ‡æ¡ˆä¾‹", "å†å²ä¸­æ ‡åº“", "ğŸ–¥ï¸", "PDF", "18.7 MB",
             "å¤§å‹æ•°æ®ä¸­å¿ƒç²¾å¯†ç©ºè°ƒä¸­æ ‡å¤ç›˜"),
            ("ä¼ä¸šä¸‰è¯åˆä¸€èµ„è´¨åŒ…", "èµ„è´¨æ–‡ä»¶", "ğŸ“‹", "ZIP", "45.2 MB",
             "è¥ä¸šæ‰§ç…§ã€å®‰å…¨è®¸å¯è¯ã€ISO è®¤è¯å…¨å¥—"),
            ("ISO9001/14001 è®¤è¯è¯ä¹¦", "èµ„è´¨æ–‡ä»¶", "ğŸ…", "PDF", "8.4 MB",
             "è´¨é‡ç®¡ç†ä¸ç¯å¢ƒç®¡ç†ä½“ç³»è®¤è¯"),
            ("ç‰¹ç§è®¾å¤‡å®‰è£…æ”¹é€ è®¸å¯è¯", "èµ„è´¨æ–‡ä»¶", "ğŸ”§", "PDF", "2.1 MB",
             "A2 çº§å‹åŠ›å®¹å™¨å®‰è£…è®¸å¯"),
        ]
        cursor.executemany(
            "INSERT INTO knowledge_base (title, category, icon, file_type, file_size, description) "
            "VALUES (?, ?, ?, ?, ?, ?)",
            seed_docs,
        )
        conn.commit()

    conn.close()


# â”€â”€ é¡¹ç›®ç®¡ç† â”€â”€

def add_project(project_name: str, current_stage: str,
                client: str = "", design_institute: str = "",
                general_contractor: str = "", applicant: str = "",
                dept: str = ""):
    """æ–°å»ºä½œæˆ˜é¡¹ç›® (Entity-Firstï¼šå«å®Œæ•´å®ä½“å…ƒæ•°æ®)ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO projects (project_name, current_stage, client, "
        "design_institute, general_contractor, applicant, dept) "
        "VALUES (?, ?, ?, ?, ?, ?, ?)",
        (project_name, current_stage, client, design_institute,
         general_contractor, applicant, dept),
    )
    new_id = cursor.lastrowid
    conn.commit()
    conn.close()
    return new_id


def get_projects():
    """è·å–æ‰€æœ‰é¡¹ç›®åˆ—è¡¨ï¼Œè¿”å› [(id, name), ...]ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute("SELECT project_id, project_name FROM projects")
    rows = cursor.fetchall()
    conn.close()
    return rows


# â”€â”€ æ‹œè®¿æ—¥å¿— â”€â”€

def insert_visit_log(project_id: int, raw_input: str, ai_parsed_data: str):
    """å°†åŸå§‹å£è¿°å’Œ AI æç‚¼ç»“æœå†™å…¥ visit_logs è¡¨ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO visit_logs (project_id, raw_input, ai_parsed_data) VALUES (?, ?, ?)",
        (project_id, raw_input, ai_parsed_data),
    )
    conn.commit()
    conn.close()


def get_all_logs(project_id: int | None = None):
    """æŸ¥è¯¢æ‹œè®¿æ—¥å¿—ï¼Œå¯æŒ‰é¡¹ç›®ç­›é€‰ï¼ŒæŒ‰ ID å€’åºè¿”å›ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    if project_id:
        cursor.execute(
            "SELECT log_id, created_at, raw_input, ai_parsed_data "
            "FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
            (project_id,),
        )
    else:
        cursor.execute(
            "SELECT log_id, created_at, raw_input, ai_parsed_data "
            "FROM visit_logs ORDER BY log_id DESC"
        )
    rows = cursor.fetchall()
    conn.close()
    return rows


def get_logs_by_project(project_id: int):
    """æŸ¥è¯¢æŒ‡å®šé¡¹ç›®çš„æ‹œè®¿æ—¥å¿—ï¼ŒæŒ‰ ID å€’åºè¿”å›ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute(
        "SELECT log_id, created_at, raw_input, ai_parsed_data "
        "FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
        (project_id,),
    )
    rows = cursor.fetchall()
    conn.close()
    return rows


# â”€â”€ ç»¼åˆæƒ…æŠ¥å­˜å‚¨ â”€â”€

def save_intelligence(project_id: int, raw_text: str, parsed_json_str: str):
    """å°†æ‹œè®¿æ—¥å¿— + å…³é”®äººæ¡£æ¡ˆä¸€èµ·å…¥åº“ã€‚"""
    import json

    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()

    # 1. å­˜æ‹œè®¿æ—¥å¿—
    cursor.execute(
        "INSERT INTO visit_logs (project_id, raw_input, ai_parsed_data) VALUES (?, ?, ?)",
        (project_id, raw_text, parsed_json_str),
    )

    # 2. æå–å¹¶å­˜å…³é”®äºº
    try:
        parsed = json.loads(parsed_json_str)
    except (json.JSONDecodeError, TypeError):
        parsed = {}

    # å…¼å®¹æ—§æ ¼å¼ stakeholders å’Œæ–°æ ¼å¼ decision_chain
    people = parsed.get("decision_chain", parsed.get("stakeholders", []))
    for person in people:
        name = person.get("name", "").strip()
        if not name:
            continue
        role = person.get("title", person.get("role", "æœªçŸ¥"))
        phone = person.get("phone")
        soft_tags = ", ".join(person.get("soft_tags", []))
        hard_profile = f"èŒåŠ¡: {role} | ç”µè¯: {phone or 'æœªè·å–'}"
        cursor.execute(
            "INSERT INTO stakeholders (name, project_id, hard_profile, soft_persona) "
            "VALUES (?, ?, ?, ?)",
            (name, project_id, hard_profile, soft_tags),
        )

    conn.commit()
    conn.close()


def get_all_projects():
    """è·å–æ‰€æœ‰é¡¹ç›® (Entity-First å¯Œæ•°æ®)ã€‚
    è¿”å› [(project_id, project_name, client, design_institute,
           general_contractor, applicant, dept), ...]
    """
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute(
        "SELECT DISTINCT project_id, project_name, "
        "COALESCE(client, ''), COALESCE(design_institute, ''), "
        "COALESCE(general_contractor, ''), COALESCE(applicant, ''), "
        "COALESCE(dept, '') "
        "FROM projects ORDER BY project_id"
    )
    rows = cursor.fetchall()
    conn.close()
    return rows


def get_project_data(project_id: int):
    """è·å–æŒ‡å®šé¡¹ç›®çš„å…³é”®äººåˆ—è¡¨å’Œå†å²æ‹œè®¿è®°å½•ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()

    # å…³é”®äººåˆ—è¡¨
    cursor.execute(
        "SELECT name, hard_profile, soft_persona FROM stakeholders WHERE project_id = ?",
        (project_id,),
    )
    stakeholders = cursor.fetchall()

    # å†å²æ‹œè®¿è®°å½•
    cursor.execute(
        "SELECT log_id, created_at, raw_input, ai_parsed_data "
        "FROM visit_logs WHERE project_id = ? ORDER BY log_id DESC",
        (project_id,),
    )
    logs = cursor.fetchall()

    conn.close()
    return stakeholders, logs


def get_user_blind_spots(user: str = "default") -> str:
    """è·å–ç”¨æˆ·çš„å†å²çŸ¥è¯†ç›²ç‚¹ï¼ˆä»æ‰€æœ‰é¡¹ç›®çš„ gap_alerts èšåˆï¼‰ã€‚"""
    import json

    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute("SELECT ai_parsed_data FROM visit_logs ORDER BY log_id DESC LIMIT 20")
    rows = cursor.fetchall()
    conn.close()

    blind_spots = []
    for row in rows:
        try:
            data = json.loads(row[0])
            for gap in data.get("gap_alerts", []):
                if gap and gap not in blind_spots:
                    blind_spots.append(gap)
        except (json.JSONDecodeError, TypeError):
            continue

    return "ã€".join(blind_spots) if blind_spots else "æ— "


def save_test_record(user: str, project_id: int, quiz: str,
                    user_answer: str, score: int, critique: str,
                    blind_spots_json: str):
    """å°†æµ‹éªŒè®°å½•æŒä¹…åŒ–å…¥åº“ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO test_records (user, project_id, quiz, user_answer, "
        "score, critique, blind_spots) VALUES (?, ?, ?, ?, ?, ?, ?)",
        (user, project_id, quiz, user_answer, score, critique, blind_spots_json),
    )
    conn.commit()
    conn.close()


def get_all_test_records():
    """è·å–å…¨å‘˜æµ‹éªŒè®°å½•ï¼ˆå…³è”é¡¹ç›®åç§°ï¼‰ã€‚"""
    conn = sqlite3.connect("sri_intel.db")
    cursor = conn.cursor()
    cursor.execute(
        "SELECT t.user, p.project_name, t.score, t.blind_spots, t.created_at "
        "FROM test_records t LEFT JOIN projects p ON t.project_id = p.project_id "
        "ORDER BY t.created_at DESC"
    )
    rows = cursor.fetchall()
    conn.close()
    return rows


if __name__ == "__main__":
    init_db()
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")

