"""
è·¯ç”±ï¼šAI èƒ½åŠ›å±‚ â€” routers/ai.py
==================================
æ¥å…¥ AIGateway (services/llm_service.py)ã€‚
7 ä¸ªç«¯ç‚¹ï¼šå…¨éƒ¨èµ°åœºæ™¯åŒ–è·¯ç”± + å…¨éƒ¨å¼ºåˆ¶è„±æ•ã€‚

âš ï¸ éšç§å®‰å…¨çº¢çº¿ï¼š
   æ‰€æœ‰ç”¨æˆ·è¾“å…¥åœ¨å‘é€ç»™ GlobalLLMRouter ä¹‹å‰ï¼Œ
   å¿…é¡»é€šè¿‡ mask_sensitive_info() è„±æ•æ¸…æ´—ã€‚
"""

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session

from models import IntelLog, Project, Stakeholder, User, UserRole
from schemas import (
    AICritiqueRequest, AIGenerateRequest, AIParseRequest, AIResponse,
)
from services.llm_service import AITask, build_ai_gateway
from utils.dependencies import get_current_user, get_db, require_role
from utils.security import mask_sensitive_info

router = APIRouter(prefix="/api/ai", tags=["AI èƒ½åŠ›å±‚"])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¾…åŠ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_gateway(llm_configs: dict | None = None):
    return build_ai_gateway(llm_configs=llm_configs)


def _get_project_context(project_id: int, db: Session) -> str:
    """èšåˆé¡¹ç›®å…¨é‡æƒ…æŠ¥ä½œä¸º AI ä¸Šä¸‹æ–‡ã€‚"""
    project = db.query(Project).filter(Project.id == project_id).first()
    if not project:
        raise HTTPException(404, f"é¡¹ç›® #{project_id} ä¸å­˜åœ¨")

    logs = (
        db.query(IntelLog)
        .filter(IntelLog.project_id == project_id)
        .order_by(IntelLog.created_at.desc())
        .limit(20)
        .all()
    )
    stakeholders = (
        db.query(Stakeholder)
        .filter(Stakeholder.project_id == project_id)
        .all()
    )

    parts = [
        f"ã€é¡¹ç›®ã€‘{project.name}",
        f"ã€å®¢æˆ·ã€‘{project.client}",
        f"ã€é˜¶æ®µã€‘{project.stage.value if project.stage else 'N/A'}",
        f"ã€èµ¢ç‡ã€‘{project.win_rate}%",
    ]
    if stakeholders:
        parts.append("ã€å…³é”®äººã€‘")
        for s in stakeholders:
            parts.append(
                f"  - {s.name} ({s.title}) æ€åº¦={s.attitude.value} å½±å“åŠ›={s.influence_weight}"
            )
    if logs:
        parts.append("ã€è¿‘æœŸæƒ…æŠ¥ã€‘")
        for log in logs[:10]:
            parts.append(f"  [{log.created_at:%Y-%m-%d}] {(log.raw_input or '')[:300]}")

    return "\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. POST /api/ai/parse-intel â€” æƒ…æŠ¥ç»“æ„åŒ–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/parse-intel", response_model=AIResponse)
def parse_intel(
    body: AIParseRequest,
    user: User = Depends(require_role(UserRole.SALES)),
):
    """
    æ–‡æœ¬ â†’ 4+1 æƒ…æŠ¥ç»“æ„åŒ–ã€‚
    åœºæ™¯: FAST_EXTRACT
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    sanitized = mask_sensitive_info(body.text)
    gw = _build_gateway(body.llm_configs)

    system_prompt = (
        "ä½ æ˜¯ä¸€åèµ„æ·±å·¥ä¸šç”µæ°”é”€å”®ä¸“å®¶ã€‚è¯·å¯¹é”€å”®æ‹œè®¿å£è¿°è®°å½•è¿›è¡Œç»“æ„åŒ–æƒ…æŠ¥æå–ã€‚"
        "ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼ˆ4+1 æƒ…æŠ¥æ¨¡å‹ï¼‰ï¼š\n"
        '{"current_status": "...", "decision_chain": [...], '
        '"competitor_info": [...], "next_steps": "...", "gap_alerts": [...]}\n'
        "ä¸¥ç¦è¾“å‡º Markdown æ ‡è®°ï¼Œåªè¿”å›åˆæ³• JSONã€‚"
    )
    try:
        result = gw.chat(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": sanitized},
            ],
            task=AITask.FAST_EXTRACT,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. POST /api/ai/generate-nba â€” NBA æŠ¥å‘Š
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/generate-nba", response_model=AIResponse)
def generate_nba(
    body: AIGenerateRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    åŸºäºé¡¹ç›®æƒ…æŠ¥ç”Ÿæˆ NBA (Next Best Action) æŠ¥å‘Šã€‚
    åœºæ™¯: HEAVY_STRATEGY
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    context = _get_project_context(body.project_id, db)
    sanitized_context = mask_sensitive_info(context)
    extra = mask_sensitive_info(body.context or "")

    gw = _build_gateway(body.llm_configs)
    prompt = (
        "ä½ æ˜¯ä¸€åç‹ è¾£çš„å·¥ä¸šé”€å”®å†›å¸ˆã€‚åŸºäºä»¥ä¸‹é¡¹ç›®æƒ…æŠ¥ï¼Œç”Ÿæˆä¸€ä»½ NBA æŠ¥å‘Šï¼š\n"
        "1. å½“å‰å±€åŠ¿åˆ¤æ–­ï¼ˆä¸€å¥è¯ï¼‰\n"
        "2. æœ€ç´§è¿«çš„ 3 ä¸ªè¡ŒåŠ¨é¡¹ï¼ˆå«è´£ä»»äººå’Œæ—¶é—´èŠ‚ç‚¹ï¼‰\n"
        "3. é£é™©é¢„è­¦\n"
        "4. èƒœç‡è¯„ä¼°åŠä¾æ®\n\n"
        f"ã€é¡¹ç›®æƒ…æŠ¥ã€‘\n{sanitized_context}\n\n"
        f"ã€é™„åŠ ä¸Šä¸‹æ–‡ã€‘\n{extra}"
    )
    try:
        result = gw.chat(
            messages=[{"role": "user", "content": prompt}],
            task=AITask.HEAVY_STRATEGY,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. POST /api/ai/generate-pitch â€” è¯æœ¯ç”Ÿæˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/generate-pitch", response_model=AIResponse)
def generate_pitch(
    body: AIGenerateRequest,
    user: User = Depends(require_role(UserRole.SALES)),
    db: Session = Depends(get_db),
):
    """
    ç”Ÿæˆé”€å”®è¯æœ¯ï¼ˆå¾®ä¿¡/é‚®ä»¶/å†…éƒ¨ç­–ç•¥/æŠ€æœ¯æ–¹æ¡ˆï¼‰ã€‚
    åœºæ™¯: HEAVY_STRATEGY
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    context = _get_project_context(body.project_id, db)
    sanitized_context = mask_sensitive_info(context)
    extra = mask_sensitive_info(body.context or "è¯·ç”Ÿæˆä¸€æ®µè·Ÿè¿›å¾®ä¿¡è¯æœ¯")

    gw = _build_gateway(body.llm_configs)
    prompt = (
        "ä½ æ˜¯ä¸€åæå…¶ä¸“ä¸šçš„å·¥ä¸šå¤§å®¢æˆ·é”€å”®æ€»ç›‘ã€‚\n"
        f"è¯·æ ¹æ®ä»¥ä¸‹é¡¹ç›®æƒ…æŠ¥ï¼Œ{extra}ã€‚\n"
        f"è¦æ±‚ä¸“ä¸šè¯šæ³ã€ä¸å‘ä¸äº¢ï¼Œä½“ç°è¡Œä¸šæ´å¯ŸåŠ›ã€‚\n\n"
        f"ã€é¡¹ç›®æƒ…æŠ¥ã€‘\n{sanitized_context}"
    )
    try:
        result = gw.chat(
            messages=[{"role": "user", "content": prompt}],
            task=AITask.HEAVY_STRATEGY,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. POST /api/ai/generate-quiz â€” ä¼´å­¦å‡ºé¢˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/generate-quiz", response_model=AIResponse)
def generate_quiz(
    body: AIGenerateRequest,
    user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    åŸºäºé¡¹ç›®æƒ…æŠ¥ç”Ÿæˆå®æˆ˜æµ‹éªŒé¢˜ã€‚
    åœºæ™¯: QUIZ_CRITIQUE
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    context = _get_project_context(body.project_id, db)
    sanitized_context = mask_sensitive_info(context)

    gw = _build_gateway(body.llm_configs)
    prompt = (
        "ä½ æ˜¯ä¸€åä¸¥è‹›çš„å·¥ä¸šé”€å”®æ•™å®˜ã€‚åŸºäºä»¥ä¸‹é¡¹ç›®æƒ…æŠ¥ï¼Œ"
        "ç”Ÿæˆä¸€é“ä¸‰ç»´å®æˆ˜æƒ…æ™¯æ¨¡æ‹Ÿé¢˜ï¼š\n"
        "1. è®¾å®šåœºæ™¯ï¼ˆå…·ä½“åˆ°äººç‰©/åœ°ç‚¹/å¯¹è¯ï¼‰\n"
        "2. æå‡ºæŒ‘æˆ˜ï¼ˆå®¢æˆ·çš„åˆéš¾/ç«å“çš„çªè¢­/å†…éƒ¨çš„æ”¿æ²»åšå¼ˆï¼‰\n"
        "3. è¦æ±‚å—è®­è€…åœ¨ 3 åˆ†é’Ÿå†…ç»™å‡ºåº”å¯¹ç­–ç•¥\n\n"
        f"ã€é¡¹ç›®æƒ…æŠ¥ã€‘\n{sanitized_context}"
    )
    try:
        result = gw.chat(
            messages=[{"role": "user", "content": prompt}],
            task=AITask.QUIZ_CRITIQUE,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. POST /api/ai/critique â€” å›ç­”è¯„ä¼°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/critique", response_model=AIResponse)
def critique_answer(
    body: AICritiqueRequest,
    user: User = Depends(get_current_user),
):
    """
    è¯„ä¼°é”€å”®å›ç­”ï¼ˆè¯„åˆ†/ç‚¹è¯„/ç›²ç‚¹ï¼‰ã€‚
    åœºæ™¯: QUIZ_CRITIQUE
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    sanitized_q = mask_sensitive_info(body.question)
    sanitized_a = mask_sensitive_info(body.answer)

    gw = _build_gateway(body.llm_configs)
    prompt = (
        "ä½ æ˜¯ä¸€åæå…¶ä¸¥è‹›çš„å·¥ä¸šé”€å”®æ€»ç›‘ã€‚è¯·è¯„ä¼°ä»¥ä¸‹å›ç­”ã€‚\n"
        "è¿”å› JSON: {\"score\": 0-100, \"critique\": \"...\", "
        "\"blind_spots\": [\"...\"]}\n"
        "ä¸¥ç¦è¾“å‡º Markdownï¼Œåªè¿”å› JSONã€‚\n\n"
        f"ã€é¢˜ç›®ã€‘\n{sanitized_q}\n\n"
        f"ã€å›ç­”ã€‘\n{sanitized_a}"
    )
    try:
        result = gw.chat(
            messages=[{"role": "user", "content": prompt}],
            task=AITask.QUIZ_CRITIQUE,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. POST /api/ai/extract-stakeholders â€” å…³é”®äººæå–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/extract-stakeholders", response_model=AIResponse)
def extract_stakeholders(
    body: AIGenerateRequest,
    user: User = Depends(require_role(UserRole.SALES)),
    db: Session = Depends(get_db),
):
    """
    ä»æƒ…æŠ¥ä¸­æ‰¹é‡æå–å…³é”®äººã€‚
    åœºæ™¯: FAST_EXTRACT
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    context = _get_project_context(body.project_id, db)
    sanitized_context = mask_sensitive_info(context)

    gw = _build_gateway(body.llm_configs)
    prompt = (
        "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å¤§å®¢æˆ·é”€å”®é¡¾é—®ã€‚è¯·ä»ä»¥ä¸‹é¡¹ç›®æƒ…æŠ¥ä¸­æå–å…³é”®äººç‰©ä¿¡æ¯ã€‚\n"
        "è¿”å› JSON æ•°ç»„: [{\"name\": \"...\", \"title\": \"...\", "
        "\"attitude\": \"support/neutral/oppose\", \"influence\": 1-10, "
        "\"reports_to\": \"...\", \"tags\": [\"...\"]}, ...]\n"
        "ä¸¥ç¦è¾“å‡º Markdownï¼Œåªè¿”å› JSON æ•°ç»„ã€‚\n\n"
        f"ã€é¡¹ç›®æƒ…æŠ¥ã€‘\n{sanitized_context}"
    )
    try:
        result = gw.chat(
            messages=[{"role": "user", "content": prompt}],
            task=AITask.FAST_EXTRACT,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. POST /api/ai/power-map â€” æƒåŠ›å…³ç³»å›¾è°±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/power-map", response_model=AIResponse)
def generate_power_map(
    body: AIGenerateRequest,
    user: User = Depends(require_role(UserRole.SALES)),
    db: Session = Depends(get_db),
):
    """
    ç”Ÿæˆ Mermaid æƒåŠ›å…³ç³»å›¾è°± + æ”»ç•¥ç­–ç•¥ã€‚
    åœºæ™¯: CODE_GEN (éœ€è¦å¼ºé€»è¾‘æ¨ç†ç”Ÿæˆ Mermaid)
    ğŸ›¡ï¸ å¼ºåˆ¶è„±æ•
    """
    project = db.query(Project).filter(Project.id == body.project_id).first()
    if not project:
        raise HTTPException(404, f"é¡¹ç›® #{body.project_id} ä¸å­˜åœ¨")

    stakeholders = (
        db.query(Stakeholder)
        .filter(Stakeholder.project_id == body.project_id)
        .all()
    )
    if not stakeholders:
        return AIResponse(result="æš‚æ— å…³é”®äººæ•°æ®ï¼Œè¯·å…ˆæ·»åŠ æˆ– AI æå–ã€‚")

    sh_csv = "\n".join(
        f"{s.name},{s.title},{s.attitude.value},{s.influence_weight},{s.reports_to or 'N/A'}"
        for s in stakeholders
    )
    sanitized_csv = mask_sensitive_info(sh_csv)

    gw = _build_gateway(body.llm_configs)
    prompt = (
        "ä½ æ˜¯ä¸€åå¤§å®¢æˆ·é”€å”®çš„æƒåŠ›å…³ç³»åˆ†æä¸“å®¶ã€‚\n"
        "åŸºäºä»¥ä¸‹å…³é”®äººæ•°æ®ï¼Œç”Ÿæˆï¼š\n"
        "1. Mermaid flowchart ï¼ˆå±•ç¤ºäººç‰©ä¹‹é—´çš„æ±‡æŠ¥å’Œå½±å“å…³ç³»ï¼‰\n"
        "2. æ”»ç•¥ç­–ç•¥ï¼ˆè°æ˜¯çªç ´å£ã€è°éœ€è¦ç»•å¼€ã€è°éœ€è¦é‡ç‚¹æ”»å…³ï¼‰\n\n"
        f"ã€å…³é”®äººæ•°æ® (å§“å,èŒä½,æ€åº¦,å½±å“åŠ›,æ±‡æŠ¥ç»™)ã€‘\n{sanitized_csv}"
    )
    try:
        result = gw.chat(
            messages=[{"role": "user", "content": prompt}],
            task=AITask.CODE_GEN,
        )
        model_used = gw.audit_log[-1].model if gw.audit_log else None
        return AIResponse(result=result, model_used=model_used)
    except Exception as e:
        return AIResponse(error=str(e)[:300])
